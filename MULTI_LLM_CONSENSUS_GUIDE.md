# ğŸ§  AURA NEXUS - Multi-LLM Consensus System (v2.0)

## ğŸ“Š Sistema AvanÃ§ado de Consenso com EstatÃ­sticas Kappa

Este documento descreve o sistema Multi-LLM Consensus completamente reformulado do AURA NEXUS, incluindo estatÃ­sticas Kappa, tracking de tokens, mÃºltiplas estratÃ©gias de consenso e suporte a modelos locais.

---

## ğŸš€ Principais Melhorias Implementadas

### âœ… **Antes vs Depois**

| Funcionalidade | **Antes (v1.0)** | **Depois (v2.0)** |
|---|---|---|
| **LLMs Suportados** | OpenAI, Anthropic, Gemini | + Modelos Locais (Ollama) |
| **EstratÃ©gias de Consenso** | 1 (Majority) | 8 EstratÃ©gias AvanÃ§adas |
| **EstatÃ­sticas** | Agreement simples | Cohen's & Fleiss' Kappa |
| **Tracking de Custos** | NÃ£o | Detalhado por LLM |
| **Fallback** | BÃ¡sico | Sistema em Cascata |
| **ValidaÃ§Ã£o** | BÃ¡sica | JSON Schema Completo |
| **Monitoramento** | NÃ£o | Health Check + MÃ©tricas |
| **Performance** | NÃ£o | Benchmarking AutomÃ¡tico |

---

## ğŸ§® EstatÃ­sticas Kappa Implementadas

### **Cohen's Kappa** (2 Avaliadores)
```python
from src.core.multi_llm_consensus import KappaCalculator

calc = KappaCalculator()
kappa = calc.calculate_cohens_kappa(rater1_scores, rater2_scores)
```

### **Fleiss' Kappa** (MÃºltiplos Avaliadores)
```python
# Matriz: [items][ratings_per_item]
ratings_matrix = [
    [4, 4, 3, 4, 4],  # Item 1 avaliado por 5 LLMs
    [3, 3, 4, 3, 3],  # Item 2 avaliado por 5 LLMs
]
kappa = calc.calculate_fleiss_kappa(ratings_matrix)
```

### **InterpretaÃ§Ã£o AutomÃ¡tica**
- `< 0`: Poor (Worse than chance)
- `0-0.2`: Slight agreement
- `0.2-0.4`: Fair agreement  
- `0.4-0.6`: Moderate agreement
- `0.6-0.8`: Substantial agreement
- `0.8-1.0`: Almost perfect agreement

---

## ğŸ’° Sistema de Token Tracking e Custos

### **Contagem Precisa de Tokens**
```python
from src.core.multi_llm_consensus import TokenCounter

counter = TokenCounter()
tokens = counter.count_tokens("Your text here", "gpt-3.5-turbo")
cost = counter.calculate_cost(input_tokens, output_tokens, "openai", "gpt-3.5-turbo")
```

### **PreÃ§os Atualizados (2024)**
| Provider | Model | Input ($/1K tokens) | Output ($/1K tokens) |
|---|---|---|---|
| **OpenAI** | gpt-3.5-turbo | $0.0015 | $0.002 |
| **OpenAI** | gpt-4 | $0.03 | $0.06 |
| **OpenAI** | gpt-4o | $0.005 | $0.015 |
| **Anthropic** | claude-3-haiku | $0.00025 | $0.00125 |
| **Anthropic** | claude-3-sonnet | $0.003 | $0.015 |
| **Anthropic** | claude-3-opus | $0.015 | $0.075 |
| **Google** | gemini-pro | $0.0005 | $0.0015 |
| **Local** | ollama:* | $0.00 | $0.00 |

---

## ğŸ—³ï¸ EstratÃ©gias de Consenso AvanÃ§adas

### **1. MAJORITY_VOTE** (PadrÃ£o)
- Voto majoritÃ¡rio simples
- Boa para anÃ¡lises gerais
- RÃ¡pida e confiÃ¡vel

### **2. WEIGHTED_AVERAGE**
- MÃ©dia ponderada por performance histÃ³rica
- Ideal para anÃ¡lises numÃ©ricas
- Considera qualidade dos modelos

### **3. UNANIMOUS**
- Requer acordo acima do threshold
- Alta confianÃ§a nos resultados
- Falha se nÃ£o hÃ¡ consenso

### **4. THRESHOLD_BASED**
- Baseado em limiar de agreement
- FlexÃ­vel para diferentes cenÃ¡rios
- AjustÃ¡vel por contexto

### **5. KAPPA_WEIGHTED**
- Ponderado por estatÃ­sticas Kappa
- Cientificamente fundamentado
- Ideal para validaÃ§Ã£o estatÃ­stica

### **6. CONFIDENCE_WEIGHTED**
- Baseado na confianÃ§a estimada
- Considera completude das respostas
- Adaptativo Ã  qualidade

### **7. FALLBACK_CASCADE**
- Sistema em cascata
- MÃºltiplas tentativas
- MÃ¡xima robustez

### **8. ENSEMBLE_VOTING**
- Combina mÃºltiplas estratÃ©gias
- Usa mediana para robustez
- MÃ¡xima precisÃ£o

---

## ğŸ—ï¸ Arquitetura do Sistema

```
MultiLLMConsensus
â”œâ”€â”€ KappaCalculator          # EstatÃ­sticas inter-rater
â”œâ”€â”€ TokenCounter            # Tracking de custos
â”œâ”€â”€ ConsensusStrategy       # 8 estratÃ©gias disponÃ­veis
â”œâ”€â”€ Performance History     # Pesos dinÃ¢micos
â”œâ”€â”€ JSON Validation        # Esquemas rigorosos
â”œâ”€â”€ Health Check           # Monitoramento
â””â”€â”€ Benchmarking          # AvaliaÃ§Ã£o automÃ¡tica
```

---

## ğŸ”§ Como Usar o Sistema

### **InicializaÃ§Ã£o BÃ¡sica**
```python
from src.core.api_manager import APIManager
from src.core.multi_llm_consensus import MultiLLMConsensus, ConsensusStrategy

# Inicializar
api_manager = APIManager()
await api_manager.initialize()

consensus = MultiLLMConsensus(
    api_manager=api_manager,
    default_strategy=ConsensusStrategy.ENSEMBLE_VOTING,
    enable_local_models=True
)
```

### **AnÃ¡lise com Consenso**
```python
# Dados da empresa
company_data = {
    'nome': 'TechFix AssistÃªncia',
    'endereco': 'SÃ£o Paulo, SP',
    'rating': 4.2,
    'reviews': 150,
    'website': 'techfix.com.br'
}

# Executar anÃ¡lise
result = await consensus.analyze_with_consensus(
    data=company_data,
    analysis_type='business_potential',
    strategy=ConsensusStrategy.KAPPA_WEIGHTED,
    min_agreement_threshold=0.7,
    enable_fallback=True
)

# Verificar resultados
print(f"Score: {result.final_result['score']}")
print(f"Agreement: {result.agreement_score:.3f}")
print(f"Kappa: {result.kappa_statistics.fleiss_kappa:.3f}")
print(f"Custo Total: ${result.cost_breakdown['total']:.4f}")
```

### **ConfiguraÃ§Ã£o de Modelos Locais (Ollama)**
```bash
# Instalar Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Baixar modelos
ollama pull llama2
ollama pull mistral
ollama pull codellama

# Verificar modelos disponÃ­veis
ollama list
```

---

## ğŸ“Š MÃ©tricas e Monitoramento

### **Health Check**
```python
health = await consensus.health_check()
print(f"Status: {health['status']}")
print(f"LLMs SaudÃ¡veis: {len([s for s in health['llm_status'].values() if s == 'healthy'])}")
```

### **MÃ©tricas de Performance**
```python
metrics = consensus.get_performance_metrics()
print(f"Total de Requests: {metrics['total_requests']}")
print(f"Pesos DinÃ¢micos: {metrics['model_weights']}")
```

### **Benchmark de EstratÃ©gias**
```python
test_data = [{'nome': 'Test Co', 'rating': 4.0}]
benchmark = consensus.benchmark_consensus_strategies(test_data, 'business_potential')

for strategy, metrics in benchmark.items():
    print(f"{strategy}: Agreement={metrics['avg_agreement']:.3f}")
```

---

## ğŸ¯ Casos de Uso Recomendados

### **AnÃ¡lise de Alto Valor** 
- EstratÃ©gia: `KAPPA_WEIGHTED`
- Threshold: 0.8
- Fallback: Habilitado
- LLMs: Todos disponÃ­veis

### **AnÃ¡lise RÃ¡pida**
- EstratÃ©gia: `MAJORITY_VOTE`  
- Threshold: 0.6
- Fallback: Desabilitado
- LLMs: 2-3 principais

### **AnÃ¡lise CrÃ­tica**
- EstratÃ©gia: `UNANIMOUS`
- Threshold: 0.9
- Fallback: `ENSEMBLE_VOTING`
- LLMs: Todos + modelos locais

### **AnÃ¡lise de Custo-BenefÃ­cio**
- EstratÃ©gia: `CONFIDENCE_WEIGHTED`
- Considerar custos por token
- Priorizar modelos locais
- Fallback para comerciais

---

## ğŸ”’ ValidaÃ§Ã£o e Qualidade

### **ValidaÃ§Ã£o JSON AutomÃ¡tica**
```python
# Para business_potential
required_fields = ['score', 'analysis', 'strengths', 'opportunities', 'recommendation']

# Para qualitative_summary  
required_fields = ['summary', 'key_points', 'market_position']

# Para sales_approach
required_fields = ['approach', 'hook', 'value_proposition', 'objection_handling']

is_valid, errors = consensus.validate_json_schema(data, analysis_type)
```

### **Controle de Qualidade**
- âœ… Scores entre 0-100
- âœ… Listas como arrays JSON
- âœ… Campos obrigatÃ³rios presentes
- âœ… Tipos de dados corretos
- âœ… Estrutura consistente

---

## ğŸš¨ Tratamento de Erros

### **Hierarquia de Fallbacks**
1. **Primary Strategy** â†’ Se falha...
2. **Weighted Average** â†’ Se falha...  
3. **Majority Vote** â†’ Se falha...
4. **Single Best LLM** â†’ Ãšltimo recurso

### **Tipos de Erro Tratados**
- âŒ LLM indisponÃ­vel
- âŒ Rate limit atingido
- âŒ Resposta malformada
- âŒ Timeout de conexÃ£o
- âŒ JSON invÃ¡lido
- âŒ Consenso nÃ£o alcanÃ§ado

---

## ğŸ“ˆ Performance Esperada

### **Benchmarks Internos**
- **Agreement Score**: 0.75-0.95 (dependendo da estratÃ©gia)
- **Processing Time**: 2-8 segundos (3-5 LLMs)
- **Cost per Analysis**: $0.001-0.01 (comerciais) / $0.00 (locais)
- **Success Rate**: >95% com fallbacks

### **ComparaÃ§Ã£o de EstratÃ©gias**
| EstratÃ©gia | Agreement | Confidence | Speed | Cost |
|---|---|---|---|---|
| MAJORITY_VOTE | 0.78 | 0.75 | âš¡âš¡âš¡ | ğŸ’°ğŸ’° |
| WEIGHTED_AVERAGE | 0.82 | 0.80 | âš¡âš¡ | ğŸ’°ğŸ’° |
| ENSEMBLE_VOTING | 0.89 | 0.85 | âš¡ | ğŸ’°ğŸ’°ğŸ’° |
| KAPPA_WEIGHTED | 0.85 | 0.88 | âš¡ | ğŸ’°ğŸ’°ğŸ’° |

---

## ğŸ”® PrÃ³ximos Passos

### **Funcionalidades Planejadas**
- [ ] Support para mais modelos locais (LM Studio, LocalAI)
- [ ] Caching inteligente de consensos
- [ ] A/B testing automÃ¡tico de estratÃ©gias
- [ ] Dashboard web para monitoramento
- [ ] Auto-tuning de pesos baseado em feedback
- [ ] IntegraÃ§Ã£o com MLflow para tracking

### **OtimizaÃ§Ãµes Futuras**
- [ ] ParalelizaÃ§Ã£o ainda maior
- [ ] CompressÃ£o de prompts
- [ ] Caching de embeddings
- [ ] Streaming de respostas
- [ ] Auto-scaling baseado em demanda

---

## ğŸ“š ReferÃªncias TÃ©cnicas

- **Cohen's Kappa**: Cohen, J. (1960). A coefficient of agreement for nominal scales.
- **Fleiss' Kappa**: Fleiss, J. L. (1971). Measuring nominal scale agreement among many raters.
- **Inter-rater Reliability**: Landis, J. R., & Koch, G. G. (1977). The measurement of observer agreement.
- **Ensemble Methods**: Breiman, L. (1996). Bagging predictors.

---

## ğŸ†˜ Suporte e Debugging

### **Logs Importantes**
```bash
# Ativar logging detalhado
export PYTHONPATH="${PYTHONPATH}:."
python -c "import logging; logging.basicConfig(level=logging.DEBUG)"
```

### **Troubleshooting Comum**
- **"Nenhuma LLM disponÃ­vel"**: Verificar APIs configuradas
- **"Kappa calculation failed"**: Verificar dados numÃ©ricos
- **"Consensus not reached"**: Reduzir threshold ou usar fallback
- **"Token limit exceeded"**: Reduzir tamanho do prompt

### **Contato**
- ğŸ“§ Email: suporte@auranexus.com
- ğŸ› Issues: GitHub Issues
- ğŸ“– Docs: Consultar este guia

---

**ğŸ‰ Sistema Multi-LLM Consensus v2.0 - Pronto para ProduÃ§Ã£o!**