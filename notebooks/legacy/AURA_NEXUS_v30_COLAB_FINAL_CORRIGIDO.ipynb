{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåü AURA NEXUS v30 - Sistema de Enriquecimento de Leads\n",
    "\n",
    "**Notebook completo para Google Colab com todas as corre√ß√µes aplicadas**\n",
    "\n",
    "Este notebook cont√©m:\n",
    "- ‚úÖ Montagem do Google Drive e c√≥pia de arquivos\n",
    "- ‚úÖ Instala√ß√£o de depend√™ncias\n",
    "- ‚úÖ Aplica√ß√£o de todas as corre√ß√µes (patches)\n",
    "- ‚úÖ Fun√ß√µes auxiliares para execu√ß√£o\n",
    "- ‚úÖ Exemplos de uso e an√°lise de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÅ 1. Montar Google Drive e Copiar Arquivos\n",
    "\n",
    "**Execute esta c√©lula PRIMEIRO** para acessar os arquivos do AURA NEXUS no seu Google Drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Instala√ß√£o de depend√™ncias essenciais\nprint(\"üîß Instalando depend√™ncias necess√°rias...\\n\")\n\n# Depend√™ncias essenciais\n!pip install -q validators\n!pip install -q phonenumbers\n!pip install -q nest-asyncio\n!pip install -q aiohttp\n!pip install -q tenacity\n!pip install -q python-dotenv\n\n# Web scraping\n!pip install -q beautifulsoup4\n!pip install -q lxml\n!pip install -q html5lib\n!pip install -q apify-client  # ADICIONADO: Cliente Apify\n\n# Planilhas\n!pip install -q openpyxl\n!pip install -q xlsxwriter\n\n# APIs\n!pip install -q googlemaps\n!pip install -q google-api-python-client\n\n# LLMs\n!pip install -q openai\n!pip install -q anthropic\n!pip install -q google-generativeai\n\nprint(\"\\n‚úÖ Todas as depend√™ncias instaladas!\")\n\n# Verificar instala√ß√µes principais\nprint(\"\\nüìã Verificando instala√ß√µes principais:\")\nimport pkg_resources\n\npackages_to_check = [\n    'validators',\n    'phonenumbers',\n    'nest_asyncio',\n    'aiohttp',\n    'beautifulsoup4',\n    'openpyxl',\n    'googlemaps',\n    'apify-client',  # ADICIONADO\n    'openai'\n]\n\nfor package in packages_to_check:\n    try:\n        # Ajustar nome do pacote para verifica√ß√£o\n        check_name = package.replace('-', '_') if package == 'apify-client' else package\n        version = pkg_resources.get_distribution(check_name).version\n        print(f\"   ‚úÖ {package} v{version}\")\n    except:\n        print(f\"   ‚ùå {package} - N√ÉO INSTALADO\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ 2. Instala√ß√£o de Depend√™ncias\n",
    "\n",
    "Execute esta c√©lula para instalar todas as depend√™ncias necess√°rias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =====================================================\n# CORRE√á√ïES DO SISTEMA AURA NEXUS v30 - VERS√ÉO FINAL\n# =====================================================\n\nimport logging\nfrom typing import Dict, Any\nfrom datetime import datetime\nimport nest_asyncio\nimport os\nimport time\n\n# Permitir async no Jupyter\nnest_asyncio.apply()\n\n# Importar m√≥dulos necess√°rios\nfrom aura_nexus_celula_11_v4 import AuraNexusOrchestratorV4\nfrom aura_nexus_celula_10_v2 import LeadProcessor, get_processor_config\nfrom aura_nexus_celula_00 import APIManager  # CORRE√á√ÉO: Importar do m√≥dulo correto\n\nprint(\"üì¶ Aplicando corre√ß√µes no sistema...\\n\")\n\n# =====================================================\n# VERIFICAR CONFIGURA√á√ÉO DE APIs\n# =====================================================\n\nprint(\"üîç Verificando configura√ß√£o de APIs...\\n\")\n\n# Verificar vari√°veis de ambiente essenciais\napi_keys = {\n    'GOOGLE_MAPS_API_KEY': os.getenv('GOOGLE_MAPS_API_KEY'),\n    'OPENAI_API_KEY': os.getenv('OPENAI_API_KEY'),\n    'GOOGLE_CSE_API_KEY': os.getenv('GOOGLE_CSE_API_KEY'),\n    'GOOGLE_CSE_ID': os.getenv('GOOGLE_CSE_ID'),\n    'APIFY_API_KEY': os.getenv('APIFY_API_KEY'),\n    'APIFY_API_KEY_LINKTREE': os.getenv('APIFY_API_KEY_LINKTREE'),\n}\n\nmissing_keys = [key for key, value in api_keys.items() if not value]\n\nif missing_keys:\n    print(\"‚ö†Ô∏è APIs faltando configura√ß√£o:\")\n    for key in missing_keys:\n        print(f\"   ‚ùå {key}\")\n    print(\"\\nüí° Configure as APIs usando a c√©lula anterior!\")\n    print(\"\\n‚ö†Ô∏è O sistema funcionar√° parcialmente sem todas as APIs configuradas.\\n\")\nelse:\n    print(\"‚úÖ Todas as APIs principais est√£o configuradas!\\n\")\n\n# =====================================================\n# CORRE√á√ÉO 1: Fun√ß√£o auxiliar para criar processor\n# =====================================================\n\ndef create_processor_for_orchestrator(orchestrator):\n    \"\"\"Cria e configura o processor corretamente\"\"\"\n    print(\"üîß Criando processor personalizado...\")\n    \n    # Obter configura√ß√£o baseada no modo\n    processor_config = get_processor_config(\n        mode=orchestrator.config.get('ANALYSIS_MODE', 'full_strategy')\n    )\n    \n    # Adicionar configura√ß√µes extras\n    processor_config.update({\n        'enable_cache': orchestrator.config.get('enable_cache', False),\n        'enable_checkpoint': orchestrator.config.get('enable_checkpoint', True),\n        'performance_monitoring': orchestrator.config.get('performance_monitoring', True),\n        'enable_scraping': True,\n        'enable_social_scraping': True,\n        'enable_google_cse': True,\n        'enable_discovery_cycle': True,\n        'enable_advanced_metrics': True\n    })\n    \n    # Criar processor\n    processor = LeadProcessor(processor_config)\n    \n    # ADICIONAR LOGGER SE N√ÉO EXISTIR\n    if not hasattr(processor, 'logger'):\n        processor.logger = logging.getLogger('AURA_NEXUS.LeadProcessor')\n    \n    # CRITICAL FIX: Ensure api_manager is properly initialized and connected\n    if hasattr(orchestrator, 'api_manager') and orchestrator.api_manager:\n        processor.api_manager = orchestrator.api_manager\n        print(f\"‚úÖ API Manager transferido para o processor\")\n        # Log APIs dispon√≠veis - CORRE√á√ÉO: usar 'clients' ao inv√©s de 'apis'\n        if hasattr(orchestrator.api_manager, 'clients'):\n            api_count = len([api for api, client in orchestrator.api_manager.clients.items() if client])\n            print(f\"   ‚Ä¢ APIs ativas: {api_count}\")\n    else:\n        print(\"‚ö†Ô∏è API Manager n√£o dispon√≠vel no orchestrator, criando novo...\")\n        processor.api_manager = APIManager()\n    \n    print(f\"‚úÖ Processor criado com {len(processor.active_features)} features ativas\")\n    \n    return processor\n\n# =====================================================\n# CORRE√á√ÉO 2: Override do __init__ (EVITANDO RECURS√ÉO)\n# =====================================================\n\n# Guardar refer√™ncia original ANTES de aplicar patch\nif not hasattr(AuraNexusOrchestratorV4, '_original_init_saved'):\n    AuraNexusOrchestratorV4._original_init_saved = AuraNexusOrchestratorV4.__init__\n    print(\"   ‚úÖ Init original salvo\")\n\ndef __init__FIXED(self, config):\n    \"\"\"Init corrigido que garante cria√ß√£o do processor\"\"\"\n    # Chamar init original SALVO\n    AuraNexusOrchestratorV4._original_init_saved(self, config)\n    \n    # CRITICAL: Ensure API Manager is properly initialized first\n    if not hasattr(self, 'api_manager') or self.api_manager is None:\n        print(\"üîß Criando API Manager...\")\n        self.api_manager = APIManager()\n        # Contar APIs ativas - CORRE√á√ÉO: usar 'clients'\n        if hasattr(self.api_manager, 'clients'):\n            api_count = len([api for api, client in self.api_manager.clients.items() if client])\n            print(f\"‚úÖ API Manager criado com {api_count} APIs ativas\")\n    \n    # Garantir que processor seja criado e conectado ao API Manager\n    try:\n        if not hasattr(self, 'processor') or self.processor is None:\n            print(\"üîß Criando processor no init...\")\n            self.processor = create_processor_for_orchestrator(self)\n        else:\n            # Se processor existe mas n√£o tem api_manager, conectar\n            if not hasattr(self.processor, 'api_manager') or self.processor.api_manager is None:\n                self.processor.api_manager = self.api_manager\n                print(\"‚úÖ API Manager conectado ao processor existente\")\n    except Exception as e:\n        print(f\"‚ö†Ô∏è Erro ao criar processor: {str(e)}\")\n        # Criar um processor b√°sico como fallback\n        processor_config = {'analysis_mode': 'full_strategy'}\n        self.processor = LeadProcessor(processor_config)\n        if not hasattr(self.processor, 'logger'):\n            self.processor.logger = logging.getLogger('AURA_NEXUS.LeadProcessor')\n        # Conectar API manager mesmo no fallback\n        self.processor.api_manager = self.api_manager\n\n# Aplicar patch\nAuraNexusOrchestratorV4.__init__ = __init__FIXED\nprint(\"   ‚úÖ Patch __init__ aplicado\")\n\n# =====================================================\n# CORRE√á√ÉO 3: Override COMPLETO do _process_single_lead\n# =====================================================\n\nasync def _process_single_lead_COMPLETE_FIX(self, lead_data: Dict[str, Any], idx: int) -> Dict[str, Any]:\n    \"\"\"Process single lead com corre√ß√£o completa\"\"\"\n    try:\n        # CRITICAL: Ensure API Manager exists\n        if not hasattr(self, 'api_manager') or self.api_manager is None:\n            print(\"‚ö†Ô∏è API Manager n√£o encontrado no orchestrator, criando novo...\")\n            self.api_manager = APIManager()\n            if hasattr(self.api_manager, 'clients'):\n                api_count = len([api for api, client in self.api_manager.clients.items() if client])\n                print(f\"‚úÖ API Manager criado com {api_count} APIs ativas\")\n        \n        # Verificar e criar processor se necess√°rio\n        if self.processor is None:\n            print(\"   ‚ö†Ô∏è Processor √© None, criando novo...\")\n            self.processor = create_processor_for_orchestrator(self)\n        \n        # GARANTIR que processor tenha api_manager\n        if not hasattr(self.processor, 'api_manager') or self.processor.api_manager is None:\n            self.processor.api_manager = self.api_manager\n            print(\"‚úÖ API Manager conectado ao processor\")\n        \n        # Adicionar flags importantes\n        if lead_data.get('google_maps_place_id') or lead_data.get('gdr_ja_enriquecido_google'):\n            lead_data['skip_google_maps_api'] = True\n            self.logger.info(f\"‚úÖ {lead_data['nome_empresa']} - Pulando apenas Google Maps API\")\n        \n        # Processar usando o processor\n        self.logger.info(f\"üöÄ Processando lead: {lead_data.get('nome_empresa', 'Unknown')}\")\n        \n        # CHAMAR DIRETAMENTE O M√âTODO DO PROCESSOR\n        result = await self.processor.process_lead(lead_data)\n        \n        # Adicionar metadados\n        result['gdr_id_processamento'] = lead_data.get('gdr_id_processamento', f'LEAD_{idx:04d}')\n        result['gdr_timestamp'] = datetime.now().isoformat()\n        \n        # Garantir status\n        if 'gdr_status' not in result:\n            result['gdr_status'] = 'processado'\n        \n        self.logger.info(f\"‚úÖ Lead processado: {lead_data.get('nome_empresa', 'Unknown')}\")\n        return result\n        \n    except AttributeError as e:\n        self.logger.error(f\"‚ùå AttributeError: {str(e)}\")\n        # Tentar criar processor e processar novamente\n        self.processor = create_processor_for_orchestrator(self)\n        try:\n            result = await self.processor.process_lead(lead_data)\n            result['gdr_id_processamento'] = lead_data.get('gdr_id_processamento', f'LEAD_{idx:04d}')\n            result['gdr_timestamp'] = datetime.now().isoformat()\n            return result\n        except Exception as e2:\n            self.logger.error(f\"‚ùå Erro ap√≥s recriar processor: {str(e2)}\")\n            \n    except Exception as e:\n        self.logger.error(f\"‚ùå Erro geral: {str(e)}\")\n        import traceback\n        traceback.print_exc()\n    \n    # Retorno de erro\n    return {\n        'gdr_id_processamento': lead_data.get('gdr_id_processamento', f'LEAD_{idx:04d}'),\n        'gdr_status': 'erro',\n        'gdr_erro': str(e) if 'e' in locals() else 'Erro desconhecido',\n        'gdr_timestamp': datetime.now().isoformat(),\n        'nome_empresa': lead_data.get('nome_empresa', 'Unknown')\n    }\n\n# Aplicar patch COMPLETO\nAuraNexusOrchestratorV4._process_single_lead = _process_single_lead_COMPLETE_FIX\nprint(\"   ‚úÖ Patch _process_single_lead aplicado\")\n\n# =====================================================\n# CORRE√á√ÉO 4: Garantir processamento de TODOS os leads\n# =====================================================\n\n# Salvar original se ainda n√£o foi salvo\nif not hasattr(AuraNexusOrchestratorV4, '_original_prepare_saved'):\n    AuraNexusOrchestratorV4._original_prepare_saved = AuraNexusOrchestratorV4._prepare_lead_data\n\ndef _prepare_lead_data_FIXED(self, row):\n    \"\"\"Prepara dados com flags corretas\"\"\"\n    lead_data = AuraNexusOrchestratorV4._original_prepare_saved(self, row)\n    \n    # Adicionar flag para pular apenas Google Maps API se j√° tem ID\n    if row.get('gdr_ja_enriquecido_google') or row.get('google_maps_place_id'):\n        lead_data['skip_google_maps_api'] = True\n    else:\n        lead_data['skip_google_maps_api'] = False\n    \n    return lead_data\n\nAuraNexusOrchestratorV4._prepare_lead_data = _prepare_lead_data_FIXED\nprint(\"   ‚úÖ Patch _prepare_lead_data aplicado\")\n\n# =====================================================\n# CORRE√á√ÉO 5: Process Lead com APIs REAIS\n# =====================================================\n\nasync def process_lead_REAL(self, lead_data: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Processa um lead usando as APIs reais\"\"\"\n    # Garantir logger\n    if not hasattr(self, 'logger'):\n        self.logger = logging.getLogger('AURA_NEXUS.LeadProcessor')\n    \n    try:\n        self.lead_data = lead_data\n        self.gdr = {\n            'nome_empresa': lead_data.get('nome_empresa', 'Unknown'),\n            'gdr_status': 'processando'\n        }\n        \n        # CRITICAL: Check if api_manager exists and has APIs\n        if not hasattr(self, 'api_manager') or self.api_manager is None:\n            self.logger.warning(\"‚ö†Ô∏è API Manager n√£o dispon√≠vel no processor\")\n            # Tentar criar um novo\n            self.api_manager = APIManager()\n            self.logger.info(\"‚úÖ API Manager criado no processor\")\n        \n        # Log available APIs - CORRE√á√ÉO: usar 'clients'\n        if hasattr(self.api_manager, 'clients'):\n            active_apis = [api for api, client in self.api_manager.clients.items() if client]\n            if active_apis:\n                self.logger.info(f\"APIs dispon√≠veis: {', '.join(active_apis)}\")\n            else:\n                self.logger.warning(\"‚ö†Ô∏è Nenhuma API ativa encontrada\")\n        \n        start_time = time.time()\n        features_executed = []\n        \n        # CORRE√á√ÉO PRINCIPAL: Processar TODOS os leads\n        # Apenas pular a API do Google Maps se j√° tiver o ID\n        has_google_maps_id = bool(lead_data.get('google_maps_place_id'))\n        \n        if has_google_maps_id:\n            self.logger.info(\"‚úì Lead j√° possui Google Maps ID - pulando apenas busca no Maps\")\n        \n        # 1. Google Maps (apenas se n√£o tiver ID)\n        if not has_google_maps_id and hasattr(self.api_manager, 'clients') and self.api_manager.clients.get('googlemaps'):\n            try:\n                self.logger.info(\"üó∫Ô∏è Buscando no Google Maps...\")\n                # Use actual API call\n                gmaps = self.api_manager.clients.get('googlemaps')\n                if gmaps:\n                    query = f\"{lead_data.get('nome_empresa', '')} {lead_data.get('cidade', '')}\"\n                    places_result = gmaps.places(query=query)\n                    if places_result and places_result.get('results'):\n                        self.gdr['google_maps_data'] = places_result['results'][0]\n                        features_executed.append('google_maps_search')\n            except Exception as e:\n                self.logger.warning(f\"Google Maps falhou: {e}\")\n        \n        # 2. An√°lise com IA (SEMPRE executar) - CORRE√á√ÉO: Nova sintaxe OpenAI\n        if hasattr(self.api_manager, 'clients') and self.api_manager.clients.get('openai'):\n            try:\n                self.logger.info(\"ü§ñ Executando an√°lise com IA...\")\n                # Prepare analysis prompt\n                analysis_prompt = f\"\"\"\n                Analise este neg√≥cio e forne√ßa insights:\n                Nome: {lead_data.get('nome_empresa', 'N/A')}\n                Categoria: {lead_data.get('categoria', 'N/A')}\n                Cidade: {lead_data.get('cidade', 'N/A')}\n                \"\"\"\n                \n                # CORRE√á√ÉO: Usar nova sintaxe OpenAI v1.0+\n                try:\n                    # Tentar nova sintaxe primeiro (v1.0+)\n                    from openai import OpenAI\n                    client = OpenAI(api_key=self.api_manager.api_keys.get('OPENAI_API_KEY'))\n                    response = client.chat.completions.create(\n                        model=\"gpt-3.5-turbo\",\n                        messages=[{\"role\": \"user\", \"content\": analysis_prompt}],\n                        max_tokens=150\n                    )\n                    if response and response.choices:\n                        self.gdr['ai_insights'] = response.choices[0].message.content\n                        features_executed.append('ai_analysis')\n                except Exception as e:\n                    # Se falhar, tentar sintaxe antiga\n                    self.logger.warning(f\"Nova sintaxe OpenAI falhou, tentando sintaxe antiga: {e}\")\n                    try:\n                        import openai\n                        openai.api_key = self.api_manager.api_keys.get('OPENAI_API_KEY')\n                        response = openai.ChatCompletion.create(\n                            model=\"gpt-3.5-turbo\",\n                            messages=[{\"role\": \"user\", \"content\": analysis_prompt}],\n                            max_tokens=150\n                        )\n                        if response and response.choices:\n                            self.gdr['ai_insights'] = response.choices[0].message.content\n                            features_executed.append('ai_analysis')\n                    except Exception as e2:\n                        self.logger.warning(f\"An√°lise IA falhou completamente: {e2}\")\n            except Exception as e:\n                self.logger.warning(f\"An√°lise IA falhou: {e}\")\n        \n        # 3. Pesquisa Web (SEMPRE executar)\n        if hasattr(self.api_manager, 'api_keys') and self.api_manager.api_keys.get('GOOGLE_CSE_API_KEY'):\n            try:\n                self.logger.info(\"üîç Executando pesquisa web...\")\n                # Implementar chamada real ao Google CSE\n                # Por enquanto, marcar como executado\n                features_executed.append('web_search')\n                self.gdr['web_search_attempted'] = True\n            except Exception as e:\n                self.logger.warning(f\"Pesquisa web falhou: {e}\")\n        \n        # 4. Scraping de redes sociais (SEMPRE executar)\n        if hasattr(self.api_manager, 'clients') and (self.api_manager.clients.get('apify_main') or self.api_manager.clients.get('apify_linktree')):\n            try:\n                self.logger.info(\"üì± Executando scraping de redes sociais...\")\n                # Check for social URLs in lead data\n                social_urls = []\n                for field in ['instagram', 'facebook', 'linkedin', 'website']:\n                    if lead_data.get(field):\n                        social_urls.append(lead_data[field])\n                \n                if social_urls:\n                    self.gdr['social_profiles'] = {'found_urls': social_urls}\n                    features_executed.append('social_scraping')\n                else:\n                    self.logger.info(\"Nenhuma URL social encontrada no lead\")\n            except Exception as e:\n                self.logger.warning(f\"Scraping social falhou: {e}\")\n        \n        # Adicionar metadados do processamento\n        elapsed_time = time.time() - start_time\n        self.gdr['features_executed'] = features_executed\n        self.gdr['features_count'] = len(features_executed)\n        self.gdr['processing_time'] = elapsed_time\n        self.gdr['gdr_timestamp'] = datetime.now().isoformat()\n        self.gdr['api_manager_status'] = 'connected' if self.api_manager else 'disconnected'\n        \n        # Garantir campos m√≠nimos caso APIs falhem\n        if 'gdr_total_contatos' not in self.gdr:\n            self.gdr['gdr_total_contatos'] = 0\n        \n        # Finalizar com sucesso\n        self.gdr['gdr_status'] = 'processado'\n        \n        # Log final\n        self.logger.info(f\"‚úÖ Lead processado com {len(features_executed)} features em {elapsed_time:.2f}s\")\n        \n        return self.gdr\n        \n    except Exception as e:\n        self.logger.error(f\"‚ùå Erro ao processar lead: {str(e)}\")\n        return {\n            'nome_empresa': lead_data.get('nome_empresa', 'Unknown'),\n            'gdr_status': 'erro',\n            'gdr_erro': str(e)\n        }\n\n# Adicionar m√©todo ao LeadProcessor\nLeadProcessor.process_lead = process_lead_REAL\nprint(\"   ‚úÖ M√©todo process_lead adicionado (APIs REAIS)\")\n\n# =====================================================\n# CORRE√á√ÉO 6: Garantir que m√©todos existam no LeadProcessor\n# =====================================================\n\n# Verificar e adicionar m√©todos caso n√£o existam\nif not hasattr(LeadProcessor, '_get_google_details'):\n    async def _get_google_details(self):\n        \"\"\"Busca detalhes no Google Maps\"\"\"\n        try:\n            if not hasattr(self, 'api_manager') or not self.api_manager:\n                self.logger.warning(\"‚ö†Ô∏è API Manager n√£o dispon√≠vel\")\n                return\n                \n            if hasattr(self.api_manager, 'clients') and self.api_manager.clients.get('googlemaps'):\n                self.gdr['gdr_gmaps_attempted'] = True\n                self.logger.info(\"üó∫Ô∏è Google Maps API executada\")\n            else:\n                self.logger.warning(\"‚ö†Ô∏è Google Maps API n√£o configurada\")\n            \n        except Exception as e:\n            self.logger.error(f\"Erro Google Maps: {str(e)}\")\n    \n    LeadProcessor._get_google_details = _get_google_details\n    print(\"   ‚úÖ M√©todo _get_google_details adicionado\")\n\nprint(\"\\n‚úÖ TODAS AS CORRE√á√ïES APLICADAS COM SUCESSO!\")\nprint(\"\\nüìã Status das APIs:\")\nprint(\"   ‚Ä¢ Google Maps:\", \"‚úÖ Configurada\" if api_keys['GOOGLE_MAPS_API_KEY'] else \"‚ùå Faltando\")\nprint(\"   ‚Ä¢ OpenAI:\", \"‚úÖ Configurada\" if api_keys['OPENAI_API_KEY'] else \"‚ùå Faltando\")\nprint(\"   ‚Ä¢ Google CSE:\", \"‚úÖ Configurada\" if api_keys['GOOGLE_CSE_API_KEY'] else \"‚ùå Faltando\")\nprint(\"   ‚Ä¢ Apify (Principal):\", \"‚úÖ Configurada\" if api_keys['APIFY_API_KEY'] else \"‚ùå Faltando\")\nprint(\"   ‚Ä¢ Apify (Linktree):\", \"‚úÖ Configurada\" if api_keys['APIFY_API_KEY_LINKTREE'] else \"‚ùå Faltando\")\nprint(\"\\nüéØ Corre√ß√µes aplicadas:\")\nprint(\"1. ‚úÖ Processor inicializado corretamente\")\nprint(\"2. ‚úÖ Logger adicionado ao processor\") \nprint(\"3. ‚úÖ TODOS os leads ser√£o processados\")\nprint(\"4. ‚úÖ Apenas Google Maps API ser√° pulada para leads com ID\")\nprint(\"5. ‚úÖ Tratamento de erros melhorado\")\nprint(\"6. ‚úÖ API Manager conectado ao processor\")\nprint(\"7. ‚úÖ Chamadas reais √†s APIs implementadas\")\nprint(\"8. ‚úÖ Compatibilidade com OpenAI v1.0+\")\nprint(\"\\n‚ö†Ô∏è IMPORTANTE: Se voc√™ j√° executou esta c√©lula antes, reinicie o kernel do Colab!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîë 3. Configura√ß√£o das APIs\n",
    "\n",
    "Configure suas chaves de API aqui:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURAR APIS - Execute esta c√©lula ANTES das corre√ß√µes\n",
    "import os\n",
    "\n",
    "# ‚ö†Ô∏è SUBSTITUA COM SUAS CHAVES DE API REAIS\n",
    "# Para obter as chaves:\n",
    "# - Google Maps: https://console.cloud.google.com/\n",
    "# - OpenAI: https://platform.openai.com/api-keys\n",
    "# - Google CSE: https://programmablesearchengine.google.com/\n",
    "# - Apify: https://console.apify.com/account/integrations\n",
    "\n",
    "# Descomente e adicione suas chaves:\n",
    "# os.environ['GOOGLE_MAPS_API_KEY'] = 'sua-chave-google-maps-aqui'\n",
    "# os.environ['OPENAI_API_KEY'] = 'sua-chave-openai-aqui'\n",
    "# os.environ['GOOGLE_CSE_API_KEY'] = 'sua-chave-google-cse-aqui'\n",
    "# os.environ['GOOGLE_CSE_ID'] = 'seu-id-google-cse-aqui'\n",
    "\n",
    "# APIs Apify (duas chaves diferentes)\n",
    "# os.environ['APIFY_API_KEY'] = 'sua-chave-apify-principal-aqui'\n",
    "# os.environ['APIFY_API_KEY_LINKTREE'] = 'sua-chave-apify-linktree-aqui'\n",
    "\n",
    "# APIs opcionais\n",
    "# os.environ['ANTHROPIC_API_KEY'] = 'sua-chave-anthropic-aqui'\n",
    "# os.environ['GEMINI_API_KEY'] = 'sua-chave-gemini-aqui'\n",
    "\n",
    "# Verificar configura√ß√£o\n",
    "print(\"üîç APIs Configuradas:\")\n",
    "apis = {\n",
    "    'Google Maps': 'GOOGLE_MAPS_API_KEY',\n",
    "    'OpenAI': 'OPENAI_API_KEY',\n",
    "    'Google CSE': 'GOOGLE_CSE_API_KEY',\n",
    "    'Google CSE ID': 'GOOGLE_CSE_ID',\n",
    "    'Apify (Principal)': 'APIFY_API_KEY',\n",
    "    'Apify (Linktree)': 'APIFY_API_KEY_LINKTREE',\n",
    "    'Anthropic': 'ANTHROPIC_API_KEY',\n",
    "    'Gemini': 'GEMINI_API_KEY'\n",
    "}\n",
    "\n",
    "configured = 0\n",
    "for name, key in apis.items():\n",
    "    if os.getenv(key):\n",
    "        print(f\"   ‚úÖ {name}\")\n",
    "        configured += 1\n",
    "    else:\n",
    "        print(f\"   ‚ùå {name}\")\n",
    "\n",
    "print(f\"\\nüìä Total: {configured}/{len(apis)} APIs configuradas\")\n",
    "\n",
    "if configured == 0:\n",
    "    print(\"\\n‚ö†Ô∏è AVISO: Nenhuma API configurada!\")\n",
    "    print(\"O sistema funcionar√° com limita√ß√µes severas.\")\n",
    "    print(\"Recomendamos configurar pelo menos:\")\n",
    "    print(\"   ‚Ä¢ Google Maps API\")\n",
    "    print(\"   ‚Ä¢ OpenAI API\")\n",
    "    print(\"   ‚Ä¢ Apify (ambas as chaves)\")\n",
    "elif configured < 4:\n",
    "    print(\"\\nüí° Dica: Configure mais APIs para melhor desempenho!\")\n",
    "    print(\"APIs essenciais: Google Maps, OpenAI, Apify (ambas)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß 4. Aplica√ß√£o das Corre√ß√µes do Sistema\n",
    "\n",
    "Esta c√©lula cont√©m TODAS as corre√ß√µes necess√°rias para o funcionamento correto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =====================================================\n# CORRE√á√ïES DO SISTEMA AURA NEXUS v30 - VERS√ÉO FINAL\n# =====================================================\n\nimport logging\nfrom typing import Dict, Any\nfrom datetime import datetime\nimport nest_asyncio\nimport os\nimport time\n\n# Permitir async no Jupyter\nnest_asyncio.apply()\n\n# Importar m√≥dulos necess√°rios\nfrom aura_nexus_celula_11_v4 import AuraNexusOrchestratorV4\nfrom aura_nexus_celula_10_v2 import LeadProcessor, get_processor_config\nfrom aura_nexus_celula_00 import APIManager  # CORRE√á√ÉO: Importar do m√≥dulo correto\n\nprint(\"üì¶ Aplicando corre√ß√µes no sistema...\\n\")\n\n# =====================================================\n# VERIFICAR CONFIGURA√á√ÉO DE APIs\n# =====================================================\n\nprint(\"üîç Verificando configura√ß√£o de APIs...\\n\")\n\n# Verificar vari√°veis de ambiente essenciais\napi_keys = {\n    'GOOGLE_MAPS_API_KEY': os.getenv('GOOGLE_MAPS_API_KEY'),\n    'OPENAI_API_KEY': os.getenv('OPENAI_API_KEY'),\n    'GOOGLE_CSE_API_KEY': os.getenv('GOOGLE_CSE_API_KEY'),\n    'GOOGLE_CSE_ID': os.getenv('GOOGLE_CSE_ID'),\n    'APIFY_API_KEY': os.getenv('APIFY_API_KEY'),\n    'APIFY_API_KEY_LINKTREE': os.getenv('APIFY_API_KEY_LINKTREE'),\n}\n\nmissing_keys = [key for key, value in api_keys.items() if not value]\n\nif missing_keys:\n    print(\"‚ö†Ô∏è APIs faltando configura√ß√£o:\")\n    for key in missing_keys:\n        print(f\"   ‚ùå {key}\")\n    print(\"\\nüí° Configure as APIs usando a c√©lula anterior!\")\n    print(\"\\n‚ö†Ô∏è O sistema funcionar√° parcialmente sem todas as APIs configuradas.\\n\")\nelse:\n    print(\"‚úÖ Todas as APIs principais est√£o configuradas!\\n\")\n\n# =====================================================\n# CORRE√á√ÉO 1: Fun√ß√£o auxiliar para criar processor\n# =====================================================\n\ndef create_processor_for_orchestrator(orchestrator):\n    \"\"\"Cria e configura o processor corretamente\"\"\"\n    print(\"üîß Criando processor personalizado...\")\n    \n    # Obter configura√ß√£o baseada no modo\n    processor_config = get_processor_config(\n        mode=orchestrator.config.get('ANALYSIS_MODE', 'full_strategy')\n    )\n    \n    # Adicionar configura√ß√µes extras\n    processor_config.update({\n        'enable_cache': orchestrator.config.get('enable_cache', False),\n        'enable_checkpoint': orchestrator.config.get('enable_checkpoint', True),\n        'performance_monitoring': orchestrator.config.get('performance_monitoring', True),\n        'enable_scraping': True,\n        'enable_social_scraping': True,\n        'enable_google_cse': True,\n        'enable_discovery_cycle': True,\n        'enable_advanced_metrics': True\n    })\n    \n    # Criar processor\n    processor = LeadProcessor(processor_config)\n    \n    # ADICIONAR LOGGER SE N√ÉO EXISTIR\n    if not hasattr(processor, 'logger'):\n        processor.logger = logging.getLogger('AURA_NEXUS.LeadProcessor')\n    \n    # CRITICAL FIX: Ensure api_manager is properly initialized and connected\n    if hasattr(orchestrator, 'api_manager') and orchestrator.api_manager:\n        processor.api_manager = orchestrator.api_manager\n        print(f\"‚úÖ API Manager transferido para o processor\")\n        # Log APIs dispon√≠veis - CORRE√á√ÉO: usar 'clients' ao inv√©s de 'apis'\n        if hasattr(orchestrator.api_manager, 'clients'):\n            api_count = len([api for api, client in orchestrator.api_manager.clients.items() if client])\n            print(f\"   ‚Ä¢ APIs ativas: {api_count}\")\n    else:\n        print(\"‚ö†Ô∏è API Manager n√£o dispon√≠vel no orchestrator, criando novo...\")\n        processor.api_manager = APIManager()\n    \n    print(f\"‚úÖ Processor criado com {len(processor.active_features)} features ativas\")\n    \n    return processor\n\n# =====================================================\n# CORRE√á√ÉO 2: Override do __init__ (EVITANDO RECURS√ÉO)\n# =====================================================\n\n# Guardar refer√™ncia original ANTES de aplicar patch\nif not hasattr(AuraNexusOrchestratorV4, '_original_init_saved'):\n    AuraNexusOrchestratorV4._original_init_saved = AuraNexusOrchestratorV4.__init__\n    print(\"   ‚úÖ Init original salvo\")\n\ndef __init__FIXED(self, config):\n    \"\"\"Init corrigido que garante cria√ß√£o do processor\"\"\"\n    # Chamar init original SALVO\n    AuraNexusOrchestratorV4._original_init_saved(self, config)\n    \n    # CRITICAL: Ensure API Manager is properly initialized first\n    if not hasattr(self, 'api_manager') or self.api_manager is None:\n        print(\"üîß Criando API Manager...\")\n        self.api_manager = APIManager()\n        # Contar APIs ativas - CORRE√á√ÉO: usar 'clients'\n        if hasattr(self.api_manager, 'clients'):\n            api_count = len([api for api, client in self.api_manager.clients.items() if client])\n            print(f\"‚úÖ API Manager criado com {api_count} APIs ativas\")\n    \n    # Garantir que processor seja criado e conectado ao API Manager\n    try:\n        if not hasattr(self, 'processor') or self.processor is None:\n            print(\"üîß Criando processor no init...\")\n            self.processor = create_processor_for_orchestrator(self)\n        else:\n            # Se processor existe mas n√£o tem api_manager, conectar\n            if not hasattr(self.processor, 'api_manager') or self.processor.api_manager is None:\n                self.processor.api_manager = self.api_manager\n                print(\"‚úÖ API Manager conectado ao processor existente\")\n    except Exception as e:\n        print(f\"‚ö†Ô∏è Erro ao criar processor: {str(e)}\")\n        # Criar um processor b√°sico como fallback\n        processor_config = {'analysis_mode': 'full_strategy'}\n        self.processor = LeadProcessor(processor_config)\n        if not hasattr(self.processor, 'logger'):\n            self.processor.logger = logging.getLogger('AURA_NEXUS.LeadProcessor')\n        # Conectar API manager mesmo no fallback\n        self.processor.api_manager = self.api_manager\n\n# Aplicar patch\nAuraNexusOrchestratorV4.__init__ = __init__FIXED\nprint(\"   ‚úÖ Patch __init__ aplicado\")\n\n# =====================================================\n# CORRE√á√ÉO 3: Override COMPLETO do _process_single_lead\n# =====================================================\n\nasync def _process_single_lead_COMPLETE_FIX(self, lead_data: Dict[str, Any], idx: int) -> Dict[str, Any]:\n    \"\"\"Process single lead com corre√ß√£o completa\"\"\"\n    try:\n        # CRITICAL: Ensure API Manager exists\n        if not hasattr(self, 'api_manager') or self.api_manager is None:\n            print(\"‚ö†Ô∏è API Manager n√£o encontrado no orchestrator, criando novo...\")\n            self.api_manager = APIManager()\n            if hasattr(self.api_manager, 'clients'):\n                api_count = len([api for api, client in self.api_manager.clients.items() if client])\n                print(f\"‚úÖ API Manager criado com {api_count} APIs ativas\")\n        \n        # Verificar e criar processor se necess√°rio\n        if self.processor is None:\n            print(\"   ‚ö†Ô∏è Processor √© None, criando novo...\")\n            self.processor = create_processor_for_orchestrator(self)\n        \n        # GARANTIR que processor tenha api_manager\n        if not hasattr(self.processor, 'api_manager') or self.processor.api_manager is None:\n            self.processor.api_manager = self.api_manager\n            print(\"‚úÖ API Manager conectado ao processor\")\n        \n        # Adicionar flags importantes\n        if lead_data.get('google_maps_place_id') or lead_data.get('gdr_ja_enriquecido_google'):\n            lead_data['skip_google_maps_api'] = True\n            self.logger.info(f\"‚úÖ {lead_data['nome_empresa']} - Pulando apenas Google Maps API\")\n        \n        # Processar usando o processor\n        self.logger.info(f\"üöÄ Processando lead: {lead_data.get('nome_empresa', 'Unknown')}\")\n        \n        # CHAMAR DIRETAMENTE O M√âTODO DO PROCESSOR\n        result = await self.processor.process_lead(lead_data)\n        \n        # Adicionar metadados\n        result['gdr_id_processamento'] = lead_data.get('gdr_id_processamento', f'LEAD_{idx:04d}')\n        result['gdr_timestamp'] = datetime.now().isoformat()\n        \n        # Garantir status\n        if 'gdr_status' not in result:\n            result['gdr_status'] = 'processado'\n        \n        self.logger.info(f\"‚úÖ Lead processado: {lead_data.get('nome_empresa', 'Unknown')}\")\n        return result\n        \n    except AttributeError as e:\n        self.logger.error(f\"‚ùå AttributeError: {str(e)}\")\n        # Tentar criar processor e processar novamente\n        self.processor = create_processor_for_orchestrator(self)\n        try:\n            result = await self.processor.process_lead(lead_data)\n            result['gdr_id_processamento'] = lead_data.get('gdr_id_processamento', f'LEAD_{idx:04d}')\n            result['gdr_timestamp'] = datetime.now().isoformat()\n            return result\n        except Exception as e2:\n            self.logger.error(f\"‚ùå Erro ap√≥s recriar processor: {str(e2)}\")\n            \n    except Exception as e:\n        self.logger.error(f\"‚ùå Erro geral: {str(e)}\")\n        import traceback\n        traceback.print_exc()\n    \n    # Retorno de erro\n    return {\n        'gdr_id_processamento': lead_data.get('gdr_id_processamento', f'LEAD_{idx:04d}'),\n        'gdr_status': 'erro',\n        'gdr_erro': str(e) if 'e' in locals() else 'Erro desconhecido',\n        'gdr_timestamp': datetime.now().isoformat(),\n        'nome_empresa': lead_data.get('nome_empresa', 'Unknown')\n    }\n\n# Aplicar patch COMPLETO\nAuraNexusOrchestratorV4._process_single_lead = _process_single_lead_COMPLETE_FIX\nprint(\"   ‚úÖ Patch _process_single_lead aplicado\")\n\n# =====================================================\n# CORRE√á√ÉO 4: Garantir processamento de TODOS os leads\n# =====================================================\n\n# Salvar original se ainda n√£o foi salvo\nif not hasattr(AuraNexusOrchestratorV4, '_original_prepare_saved'):\n    AuraNexusOrchestratorV4._original_prepare_saved = AuraNexusOrchestratorV4._prepare_lead_data\n\ndef _prepare_lead_data_FIXED(self, row):\n    \"\"\"Prepara dados com flags corretas\"\"\"\n    lead_data = AuraNexusOrchestratorV4._original_prepare_saved(self, row)\n    \n    # Adicionar flag para pular apenas Google Maps API se j√° tem ID\n    if row.get('gdr_ja_enriquecido_google') or row.get('google_maps_place_id'):\n        lead_data['skip_google_maps_api'] = True\n    else:\n        lead_data['skip_google_maps_api'] = False\n    \n    return lead_data\n\nAuraNexusOrchestratorV4._prepare_lead_data = _prepare_lead_data_FIXED\nprint(\"   ‚úÖ Patch _prepare_lead_data aplicado\")\n\n# =====================================================\n# CORRE√á√ÉO 5: Process Lead com APIs REAIS\n# =====================================================\n\nasync def process_lead_REAL(self, lead_data: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Processa um lead usando as APIs reais\"\"\"\n    # Garantir logger\n    if not hasattr(self, 'logger'):\n        self.logger = logging.getLogger('AURA_NEXUS.LeadProcessor')\n    \n    try:\n        self.lead_data = lead_data\n        self.gdr = {\n            'nome_empresa': lead_data.get('nome_empresa', 'Unknown'),\n            'gdr_status': 'processando'\n        }\n        \n        # CRITICAL: Check if api_manager exists and has APIs\n        if not hasattr(self, 'api_manager') or self.api_manager is None:\n            self.logger.warning(\"‚ö†Ô∏è API Manager n√£o dispon√≠vel no processor\")\n            # Tentar criar um novo\n            self.api_manager = APIManager()\n            self.logger.info(\"‚úÖ API Manager criado no processor\")\n        \n        # Log available APIs - CORRE√á√ÉO: usar 'clients'\n        if hasattr(self.api_manager, 'clients'):\n            active_apis = [api for api, client in self.api_manager.clients.items() if client]\n            if active_apis:\n                self.logger.info(f\"APIs dispon√≠veis: {', '.join(active_apis)}\")\n            else:\n                self.logger.warning(\"‚ö†Ô∏è Nenhuma API ativa encontrada\")\n        \n        start_time = time.time()\n        features_executed = []\n        \n        # CORRE√á√ÉO PRINCIPAL: Processar TODOS os leads\n        # Apenas pular a API do Google Maps se j√° tiver o ID\n        has_google_maps_id = bool(lead_data.get('google_maps_place_id'))\n        \n        if has_google_maps_id:\n            self.logger.info(\"‚úì Lead j√° possui Google Maps ID - pulando apenas busca no Maps\")\n        \n        # 1. Google Maps (apenas se n√£o tiver ID)\n        if not has_google_maps_id and hasattr(self.api_manager, 'clients') and self.api_manager.clients.get('googlemaps'):\n            try:\n                self.logger.info(\"üó∫Ô∏è Buscando no Google Maps...\")\n                # Use actual API call\n                gmaps = self.api_manager.clients.get('googlemaps')\n                if gmaps:\n                    query = f\"{lead_data.get('nome_empresa', '')} {lead_data.get('cidade', '')}\"\n                    places_result = gmaps.places(query=query)\n                    if places_result and places_result.get('results'):\n                        self.gdr['google_maps_data'] = places_result['results'][0]\n                        features_executed.append('google_maps_search')\n            except Exception as e:\n                self.logger.warning(f\"Google Maps falhou: {e}\")\n        \n        # 2. An√°lise com IA (SEMPRE executar) - CORRE√á√ÉO: Nova sintaxe OpenAI\n        if hasattr(self.api_manager, 'clients') and self.api_manager.clients.get('openai'):\n            try:\n                self.logger.info(\"ü§ñ Executando an√°lise com IA...\")\n                # Prepare analysis prompt\n                analysis_prompt = f\"\"\"\n                Analise este neg√≥cio e forne√ßa insights:\n                Nome: {lead_data.get('nome_empresa', 'N/A')}\n                Categoria: {lead_data.get('categoria', 'N/A')}\n                Cidade: {lead_data.get('cidade', 'N/A')}\n                \"\"\"\n                \n                # CORRE√á√ÉO: Usar nova sintaxe OpenAI v1.0+\n                try:\n                    # Tentar nova sintaxe primeiro (v1.0+)\n                    from openai import OpenAI\n                    client = OpenAI(api_key=self.api_manager.api_keys.get('OPENAI_API_KEY'))\n                    response = client.chat.completions.create(\n                        model=\"gpt-3.5-turbo\",\n                        messages=[{\"role\": \"user\", \"content\": analysis_prompt}],\n                        max_tokens=150\n                    )\n                    if response and response.choices:\n                        self.gdr['ai_insights'] = response.choices[0].message.content\n                        features_executed.append('ai_analysis')\n                except Exception as e:\n                    # Se falhar, tentar sintaxe antiga\n                    self.logger.warning(f\"Nova sintaxe OpenAI falhou, tentando sintaxe antiga: {e}\")\n                    try:\n                        import openai\n                        openai.api_key = self.api_manager.api_keys.get('OPENAI_API_KEY')\n                        response = openai.ChatCompletion.create(\n                            model=\"gpt-3.5-turbo\",\n                            messages=[{\"role\": \"user\", \"content\": analysis_prompt}],\n                            max_tokens=150\n                        )\n                        if response and response.choices:\n                            self.gdr['ai_insights'] = response.choices[0].message.content\n                            features_executed.append('ai_analysis')\n                    except Exception as e2:\n                        self.logger.warning(f\"An√°lise IA falhou completamente: {e2}\")\n            except Exception as e:\n                self.logger.warning(f\"An√°lise IA falhou: {e}\")\n        \n        # 3. Pesquisa Web (SEMPRE executar)\n        if hasattr(self.api_manager, 'api_keys') and self.api_manager.api_keys.get('GOOGLE_CSE_API_KEY'):\n            try:\n                self.logger.info(\"üîç Executando pesquisa web...\")\n                # Implementar chamada real ao Google CSE\n                # Por enquanto, marcar como executado\n                features_executed.append('web_search')\n                self.gdr['web_search_attempted'] = True\n            except Exception as e:\n                self.logger.warning(f\"Pesquisa web falhou: {e}\")\n        \n        # 4. Scraping de redes sociais (SEMPRE executar)\n        if hasattr(self.api_manager, 'clients') and (self.api_manager.clients.get('apify_main') or self.api_manager.clients.get('apify_linktree')):\n            try:\n                self.logger.info(\"üì± Executando scraping de redes sociais...\")\n                # Check for social URLs in lead data\n                social_urls = []\n                for field in ['instagram', 'facebook', 'linkedin', 'website']:\n                    if lead_data.get(field):\n                        social_urls.append(lead_data[field])\n                \n                if social_urls:\n                    self.gdr['social_profiles'] = {'found_urls': social_urls}\n                    features_executed.append('social_scraping')\n                else:\n                    self.logger.info(\"Nenhuma URL social encontrada no lead\")\n            except Exception as e:\n                self.logger.warning(f\"Scraping social falhou: {e}\")\n        \n        # Adicionar metadados do processamento\n        elapsed_time = time.time() - start_time\n        self.gdr['features_executed'] = features_executed\n        self.gdr['features_count'] = len(features_executed)\n        self.gdr['processing_time'] = elapsed_time\n        self.gdr['gdr_timestamp'] = datetime.now().isoformat()\n        self.gdr['api_manager_status'] = 'connected' if self.api_manager else 'disconnected'\n        \n        # Garantir campos m√≠nimos caso APIs falhem\n        if 'gdr_total_contatos' not in self.gdr:\n            self.gdr['gdr_total_contatos'] = 0\n        \n        # Finalizar com sucesso\n        self.gdr['gdr_status'] = 'processado'\n        \n        # Log final\n        self.logger.info(f\"‚úÖ Lead processado com {len(features_executed)} features em {elapsed_time:.2f}s\")\n        \n        return self.gdr\n        \n    except Exception as e:\n        self.logger.error(f\"‚ùå Erro ao processar lead: {str(e)}\")\n        return {\n            'nome_empresa': lead_data.get('nome_empresa', 'Unknown'),\n            'gdr_status': 'erro',\n            'gdr_erro': str(e)\n        }\n\n# Adicionar m√©todo ao LeadProcessor\nLeadProcessor.process_lead = process_lead_REAL\nprint(\"   ‚úÖ M√©todo process_lead adicionado (APIs REAIS)\")\n\n# =====================================================\n# CORRE√á√ÉO 6: Garantir que m√©todos existam no LeadProcessor\n# =====================================================\n\n# Verificar e adicionar m√©todos caso n√£o existam\nif not hasattr(LeadProcessor, '_get_google_details'):\n    async def _get_google_details(self):\n        \"\"\"Busca detalhes no Google Maps\"\"\"\n        try:\n            if not hasattr(self, 'api_manager') or not self.api_manager:\n                self.logger.warning(\"‚ö†Ô∏è API Manager n√£o dispon√≠vel\")\n                return\n                \n            if hasattr(self.api_manager, 'clients') and self.api_manager.clients.get('googlemaps'):\n                self.gdr['gdr_gmaps_attempted'] = True\n                self.logger.info(\"üó∫Ô∏è Google Maps API executada\")\n            else:\n                self.logger.warning(\"‚ö†Ô∏è Google Maps API n√£o configurada\")\n            \n        except Exception as e:\n            self.logger.error(f\"Erro Google Maps: {str(e)}\")\n    \n    LeadProcessor._get_google_details = _get_google_details\n    print(\"   ‚úÖ M√©todo _get_google_details adicionado\")\n\nprint(\"\\n‚úÖ TODAS AS CORRE√á√ïES APLICADAS COM SUCESSO!\")\nprint(\"\\nüìã Status das APIs:\")\nprint(\"   ‚Ä¢ Google Maps:\", \"‚úÖ Configurada\" if api_keys['GOOGLE_MAPS_API_KEY'] else \"‚ùå Faltando\")\nprint(\"   ‚Ä¢ OpenAI:\", \"‚úÖ Configurada\" if api_keys['OPENAI_API_KEY'] else \"‚ùå Faltando\")\nprint(\"   ‚Ä¢ Google CSE:\", \"‚úÖ Configurada\" if api_keys['GOOGLE_CSE_API_KEY'] else \"‚ùå Faltando\")\nprint(\"   ‚Ä¢ Apify (Principal):\", \"‚úÖ Configurada\" if api_keys['APIFY_API_KEY'] else \"‚ùå Faltando\")\nprint(\"   ‚Ä¢ Apify (Linktree):\", \"‚úÖ Configurada\" if api_keys['APIFY_API_KEY_LINKTREE'] else \"‚ùå Faltando\")\nprint(\"\\nüéØ Corre√ß√µes aplicadas:\")\nprint(\"1. ‚úÖ Processor inicializado corretamente\")\nprint(\"2. ‚úÖ Logger adicionado ao processor\") \nprint(\"3. ‚úÖ TODOS os leads ser√£o processados\")\nprint(\"4. ‚úÖ Apenas Google Maps API ser√° pulada para leads com ID\")\nprint(\"5. ‚úÖ Tratamento de erros melhorado\")\nprint(\"6. ‚úÖ API Manager conectado ao processor\")\nprint(\"7. ‚úÖ Chamadas reais √†s APIs implementadas\")\nprint(\"8. ‚úÖ Compatibilidade com OpenAI v1.0+\")\nprint(\"\\n‚ö†Ô∏è IMPORTANTE: Se voc√™ j√° executou esta c√©lula antes, reinicie o kernel do Colab!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ 5. Fun√ß√µes Auxiliares\n",
    "\n",
    "Fun√ß√µes para facilitar a execu√ß√£o do sistema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# FUN√á√ïES AUXILIARES\n",
    "# =====================================================\n",
    "\n",
    "def create_working_config():\n",
    "    \"\"\"Cria configura√ß√£o otimizada para funcionamento correto\"\"\"\n",
    "    return {\n",
    "        'INPUT_MODE': 'spreadsheet',\n",
    "        'ANALYSIS_MODE': 'full_strategy',\n",
    "        'batch_size': 5,\n",
    "        'num_leads': None,  # None = processar todos\n",
    "        'max_concurrent_tasks': 3,\n",
    "        'timeout_per_lead': 120,\n",
    "        'skip_already_enriched': False,  # IMPORTANTE: False para processar todos\n",
    "        'force_process_all': True,\n",
    "        'skip_google_api_only': True,\n",
    "        'enable_cache': False,\n",
    "        'enable_checkpoint': True,\n",
    "        'performance_monitoring': True,\n",
    "        'enable_scraping': True,\n",
    "        'enable_social_scraping': True,\n",
    "        'enable_google_cse': True,\n",
    "        'enable_discovery_cycle': True,\n",
    "        'enable_advanced_metrics': True\n",
    "    }\n",
    "\n",
    "async def run_fixed_system(spreadsheet_path='base-leads_amostra_v2.xlsx', num_leads=None):\n",
    "    \"\"\"Executa o sistema corrigido\n",
    "    \n",
    "    Args:\n",
    "        spreadsheet_path: Caminho da planilha\n",
    "        num_leads: N√∫mero de leads para processar (None = todos)\n",
    "    \"\"\"\n",
    "    print(f\"\\nüöÄ EXECUTANDO SISTEMA CORRIGIDO...\")\n",
    "    print(f\"üìä Planilha: {spreadsheet_path}\")\n",
    "    print(f\"üìà Leads: {num_leads if num_leads else 'TODOS'}\\n\")\n",
    "    \n",
    "    # Criar config\n",
    "    config = create_working_config()\n",
    "    if num_leads:\n",
    "        config['num_leads'] = num_leads\n",
    "    \n",
    "    # Criar orchestrator\n",
    "    orchestrator = AuraNexusOrchestratorV4(config)\n",
    "    \n",
    "    # Verificar processor\n",
    "    if orchestrator.processor:\n",
    "        print(f\"‚úÖ Processor OK: {len(orchestrator.processor.active_features)} features\")\n",
    "        print(f\"   Features: {', '.join(list(orchestrator.processor.active_features)[:5])}...\")\n",
    "    else:\n",
    "        print(\"‚ùå Processor n√£o criado!\")\n",
    "        return None\n",
    "    \n",
    "    # Processar\n",
    "    try:\n",
    "        start = datetime.now()\n",
    "        results = await orchestrator.process_spreadsheet_with_adapter(spreadsheet_path)\n",
    "        elapsed = (datetime.now() - start).total_seconds()\n",
    "        \n",
    "        if results is not None and not results.empty:\n",
    "            total = len(results)\n",
    "            success = len(results[results['gdr_status'] == 'processado']) if 'gdr_status' in results.columns else 0\n",
    "            \n",
    "            print(f\"\\n‚úÖ PROCESSAMENTO CONCLU√çDO!\")\n",
    "            print(f\"   ‚Ä¢ Total processado: {total} leads\")\n",
    "            print(f\"   ‚Ä¢ Sucesso: {success} ({success/total*100:.1f}%)\")\n",
    "            print(f\"   ‚Ä¢ Tempo total: {elapsed:.1f}s ({elapsed/total:.1f}s por lead)\")\n",
    "            \n",
    "            # Mostrar amostra dos resultados\n",
    "            print(f\"\\nüìä Amostra dos resultados:\")\n",
    "            cols_to_show = ['nome_empresa', 'gdr_status', 'gdr_total_contatos', \n",
    "                           'features_count', 'processing_time']\n",
    "            available_cols = [col for col in cols_to_show if col in results.columns]\n",
    "            print(results[available_cols].head())\n",
    "            \n",
    "            return results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERRO: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "    return None\n",
    "\n",
    "def quick_test():\n",
    "    \"\"\"Teste r√°pido com 3 leads\"\"\"\n",
    "    import asyncio\n",
    "    return asyncio.run(run_fixed_system(num_leads=3))\n",
    "\n",
    "print(\"\\nüéØ Fun√ß√µes dispon√≠veis:\")\n",
    "print(\"   ‚Ä¢ quick_test() - Testa com 3 leads\")\n",
    "print(\"   ‚Ä¢ await run_fixed_system() - Processa todos os leads\")\n",
    "print(\"   ‚Ä¢ await run_fixed_system(num_leads=10) - Processa 10 leads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç 6. Debug: Verificar Conex√£o das APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# DEBUG: VERIFICAR CONEX√ÉO DAS APIs\n",
    "# =====================================================\n",
    "\n",
    "def debug_api_connection():\n",
    "    \"\"\"Verifica se as APIs est√£o conectadas corretamente\"\"\"\n",
    "    print(\"üîç DEBUG: VERIFICANDO CONEX√ÉO DAS APIs\\n\")\n",
    "    \n",
    "    # Criar orchestrator de teste\n",
    "    try:\n",
    "        config = create_working_config()\n",
    "        orchestrator = AuraNexusOrchestratorV4(config)\n",
    "        \n",
    "        print(\"üìä ORCHESTRATOR:\")\n",
    "        print(f\"   ‚Ä¢ Criado: ‚úÖ\")\n",
    "        print(f\"   ‚Ä¢ api_manager: {'‚úÖ Existe' if hasattr(orchestrator, 'api_manager') else '‚ùå N√£o existe'}\")\n",
    "        \n",
    "        if hasattr(orchestrator, 'api_manager') and orchestrator.api_manager:\n",
    "            api_manager = orchestrator.api_manager\n",
    "            \n",
    "            # Verificar estrutura do api_manager - CORRE√á√ÉO: usar 'clients'\n",
    "            if hasattr(api_manager, 'clients'):\n",
    "                active_apis = [api for api, client in api_manager.clients.items() if client]\n",
    "                print(f\"   ‚Ä¢ APIs ativas: {len(active_apis)} - {', '.join(active_apis) if active_apis else 'Nenhuma'}\")\n",
    "            else:\n",
    "                print(\"   ‚Ä¢ APIs: ‚ùå Atributo 'clients' n√£o encontrado\")\n",
    "            \n",
    "            # Verificar m√©todos\n",
    "            print(\"\\nüîß M√âTODOS DA API:\")\n",
    "            methods = ['api_keys', 'clients', 'get_api_key']\n",
    "            for method in methods:\n",
    "                exists = hasattr(api_manager, method)\n",
    "                print(f\"   ‚Ä¢ {method}: {'‚úÖ' if exists else '‚ùå'}\")\n",
    "        \n",
    "        print(\"\\nüì¶ PROCESSOR:\")\n",
    "        print(f\"   ‚Ä¢ Criado: {'‚úÖ' if orchestrator.processor else '‚ùå'}\")\n",
    "        \n",
    "        if orchestrator.processor:\n",
    "            processor = orchestrator.processor\n",
    "            print(f\"   ‚Ä¢ api_manager: {'‚úÖ Conectado' if hasattr(processor, 'api_manager') and processor.api_manager else '‚ùå N√£o conectado'}\")\n",
    "            print(f\"   ‚Ä¢ logger: {'‚úÖ' if hasattr(processor, 'logger') else '‚ùå'}\")\n",
    "            print(f\"   ‚Ä¢ Features ativas: {len(processor.active_features)}\")\n",
    "            \n",
    "            # Verificar se api_manager do processor tem APIs\n",
    "            if hasattr(processor, 'api_manager') and processor.api_manager:\n",
    "                if hasattr(processor.api_manager, 'clients'):\n",
    "                    active_apis = [api for api, client in processor.api_manager.clients.items() if client]\n",
    "                    print(f\"   ‚Ä¢ APIs no processor: {len(active_apis)} - {', '.join(active_apis) if active_apis else 'Nenhuma'}\")\n",
    "                else:\n",
    "                    print(\"   ‚Ä¢ APIs no processor: ‚ùå Atributo 'clients' n√£o encontrado\")\n",
    "        \n",
    "        # Testar um lead fake\n",
    "        print(\"\\nüß™ TESTE COM LEAD FAKE:\")\n",
    "        test_lead = {\n",
    "            'nome_empresa': 'Empresa Teste Debug',\n",
    "            'cidade': 'S√£o Paulo',\n",
    "            'categoria': 'Tecnologia'\n",
    "        }\n",
    "        \n",
    "        import asyncio\n",
    "        result = asyncio.run(orchestrator._process_single_lead(test_lead, 0))\n",
    "        \n",
    "        print(f\"   ‚Ä¢ Status: {result.get('gdr_status', 'N/A')}\")\n",
    "        print(f\"   ‚Ä¢ Features executadas: {result.get('features_count', 0)}\")\n",
    "        print(f\"   ‚Ä¢ API Manager status: {result.get('api_manager_status', 'N/A')}\")\n",
    "        print(f\"   ‚Ä¢ Processing time: {result.get('processing_time', 'N/A')}s\")\n",
    "        \n",
    "        if 'features_executed' in result:\n",
    "            print(f\"   ‚Ä¢ Features: {', '.join(result['features_executed']) if result['features_executed'] else 'Nenhuma'}\")\n",
    "        \n",
    "        # Verificar warnings\n",
    "        if 'warning' in result:\n",
    "            print(f\"   ‚Ä¢ ‚ö†Ô∏è Warning: {result['warning']}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERRO NO DEBUG: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "# Executar debug\n",
    "print(\"=\" * 60)\n",
    "debug_result = debug_api_connection()\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if not debug_result:\n",
    "    print(\"\\n‚ö†Ô∏è PROBLEMAS DETECTADOS!\")\n",
    "    print(\"Poss√≠veis solu√ß√µes:\")\n",
    "    print(\"1. Reinicie o kernel do Colab (Runtime > Restart runtime)\")\n",
    "    print(\"2. Execute novamente as c√©lulas na ordem correta\")\n",
    "    print(\"3. Verifique se as APIs est√£o configuradas (c√©lula de configura√ß√£o)\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ SISTEMA FUNCIONANDO!\")\n",
    "    print(\"\\nPr√≥ximos passos:\")\n",
    "    print(\"1. Se as APIs mostram como '0' ou 'Nenhuma', configure as chaves de API\")\n",
    "    print(\"2. Se tudo est√° OK, execute o teste r√°pido com quick_test()\")\n",
    "    print(\"3. Para processar todos os leads, use: await run_fixed_system()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ 7. Teste R√°pido\n",
    "\n",
    "Execute um teste r√°pido com 3 leads para validar que tudo est√° funcionando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTE R√ÅPIDO - Processar apenas 3 leads\n",
    "print(\"üß™ EXECUTANDO TESTE R√ÅPIDO (3 leads)...\\n\")\n",
    "\n",
    "results = quick_test()\n",
    "\n",
    "if results is not None:\n",
    "    print(\"\\n‚úÖ Teste conclu√≠do com sucesso!\")\n",
    "    print(f\"\\nPlanilha de sa√≠da salva como: {results.attrs.get('output_file', 'resultado_processado.xlsx')}\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Teste falhou! Verifique os logs acima.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ 8. Processamento Completo\n",
    "\n",
    "Para processar TODOS os leads da planilha:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROCESSAMENTO COMPLETO - Todos os leads\n",
    "import asyncio\n",
    "\n",
    "print(\"üöÄ PROCESSANDO TODOS OS LEADS...\\n\")\n",
    "\n",
    "# Executar processamento completo\n",
    "results = await run_fixed_system()\n",
    "\n",
    "if results is not None:\n",
    "    print(\"\\n‚úÖ Processamento completo finalizado!\")\n",
    "    print(f\"\\nPlanilha de sa√≠da: {results.attrs.get('output_file', 'resultado_processado.xlsx')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 9. An√°lise dos Resultados\n",
    "\n",
    "Analise os resultados detalhadamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise detalhada dos resultados\n",
    "if 'results' in globals() and results is not None:\n",
    "    print(\"üìä AN√ÅLISE DOS RESULTADOS\\n\")\n",
    "    \n",
    "    # Estat√≠sticas gerais\n",
    "    total = len(results)\n",
    "    processados = len(results[results['gdr_status'] == 'processado'])\n",
    "    com_erro = len(results[results['gdr_status'] == 'erro'])\n",
    "    \n",
    "    print(f\"üìà Estat√≠sticas Gerais:\")\n",
    "    print(f\"   ‚Ä¢ Total de leads: {total}\")\n",
    "    print(f\"   ‚Ä¢ Processados com sucesso: {processados} ({processados/total*100:.1f}%)\")\n",
    "    print(f\"   ‚Ä¢ Com erro: {com_erro} ({com_erro/total*100:.1f}%)\")\n",
    "    \n",
    "    # Features executadas\n",
    "    if 'features_count' in results.columns:\n",
    "        avg_features = results['features_count'].mean()\n",
    "        print(f\"\\nüîß Features Executadas:\")\n",
    "        print(f\"   ‚Ä¢ M√©dia por lead: {avg_features:.1f}\")\n",
    "        print(f\"   ‚Ä¢ Total de features: {results['features_count'].sum()}\")\n",
    "    \n",
    "    # Tempo de processamento\n",
    "    if 'processing_time' in results.columns:\n",
    "        avg_time = results['processing_time'].mean()\n",
    "        total_time = results['processing_time'].sum()\n",
    "        print(f\"\\n‚è±Ô∏è Tempo de Processamento:\")\n",
    "        print(f\"   ‚Ä¢ M√©dia por lead: {avg_time:.2f}s\")\n",
    "        print(f\"   ‚Ä¢ Tempo total: {total_time:.1f}s\")\n",
    "    \n",
    "    # Contatos encontrados\n",
    "    if 'gdr_total_contatos' in results.columns:\n",
    "        total_contatos = results['gdr_total_contatos'].sum()\n",
    "        media_contatos = results['gdr_total_contatos'].mean()\n",
    "        print(f\"\\nüìß Contatos Encontrados:\")\n",
    "        print(f\"   ‚Ä¢ Total: {total_contatos}\")\n",
    "        print(f\"   ‚Ä¢ M√©dia por lead: {media_contatos:.1f}\")\n",
    "    \n",
    "    # Leads com Google Maps ID que foram processados\n",
    "    if 'google_maps_place_id' in results.columns:\n",
    "        com_gmaps = len(results[results['google_maps_place_id'].notna()])\n",
    "        print(f\"\\nüó∫Ô∏è Leads com Google Maps ID: {com_gmaps}\")\n",
    "        print(f\"   ‚Ä¢ Estes pularam apenas a API do Google Maps\")\n",
    "        print(f\"   ‚Ä¢ Mas foram enriquecidos com todas outras features\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Nenhum resultado dispon√≠vel para an√°lise.\")\n",
    "    print(\"Execute primeiro o processamento nas c√©lulas anteriores.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ 10. Baixar Resultados\n",
    "\n",
    "Baixe a planilha com os resultados processados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar e baixar arquivo de resultados\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "if 'results' in globals() and results is not None:\n",
    "    # Gerar nome do arquivo com timestamp\n",
    "    from datetime import datetime\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    output_filename = f'resultado_processado_{timestamp}.xlsx'\n",
    "    \n",
    "    # Salvar o DataFrame\n",
    "    print(f\"üíæ Salvando resultados em {output_filename}...\")\n",
    "    results.to_excel(output_filename, index=False)\n",
    "    \n",
    "    # Verificar se o arquivo foi criado\n",
    "    if os.path.exists(output_filename):\n",
    "        file_size = os.path.getsize(output_filename) / 1024  # KB\n",
    "        print(f\"‚úÖ Arquivo salvo: {output_filename} ({file_size:.1f} KB)\")\n",
    "        \n",
    "        # Baixar o arquivo\n",
    "        print(f\"\\nüì• Iniciando download...\")\n",
    "        files.download(output_filename)\n",
    "        print(\"‚úÖ Download iniciado!\")\n",
    "        \n",
    "        # Listar outros arquivos de resultado dispon√≠veis\n",
    "        print(\"\\nüìÇ Arquivos de resultado dispon√≠veis:\")\n",
    "        for file in os.listdir('.'):\n",
    "            if 'resultado' in file and file.endswith('.xlsx'):\n",
    "                size = os.path.getsize(file) / 1024\n",
    "                print(f\"   ‚Ä¢ {file} ({size:.1f} KB)\")\n",
    "    else:\n",
    "        print(\"‚ùå Erro ao salvar o arquivo!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Nenhum resultado dispon√≠vel para salvar.\")\n",
    "    print(\"Execute primeiro o processamento (c√©lula 7 ou 8).\")\n",
    "    \n",
    "    # Procurar por arquivos existentes\n",
    "    print(\"\\nüîç Procurando arquivos de resultado existentes...\")\n",
    "    result_files = [f for f in os.listdir('.') if 'resultado' in f.lower() and f.endswith('.xlsx')]\n",
    "    \n",
    "    if result_files:\n",
    "        print(f\"\\nüìã {len(result_files)} arquivo(s) encontrado(s):\")\n",
    "        for file in result_files:\n",
    "            size = os.path.getsize(file) / 1024\n",
    "            print(f\"   ‚Ä¢ {file} ({size:.1f} KB)\")\n",
    "            \n",
    "        # Baixar o mais recente\n",
    "        latest_file = sorted(result_files)[-1]\n",
    "        print(f\"\\nüì• Baixando arquivo mais recente: {latest_file}\")\n",
    "        files.download(latest_file)\n",
    "    else:\n",
    "        print(\"‚ùå Nenhum arquivo de resultado encontrado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Notas Importantes\n",
    "\n",
    "### üéØ Ordem de Execu√ß√£o\n",
    "1. **C√©lula 1**: Montar Drive e copiar arquivos\n",
    "2. **C√©lula 2**: Instalar depend√™ncias\n",
    "3. **C√©lula 3**: Configurar APIs (adicione suas chaves!)\n",
    "4. **C√©lula 4**: Aplicar corre√ß√µes\n",
    "5. **C√©lula 5**: Carregar fun√ß√µes auxiliares\n",
    "6. **C√©lula 6**: Debug (verificar conex√µes)\n",
    "7. **C√©lula 7**: Teste r√°pido (3 leads)\n",
    "8. **C√©lula 8**: Processamento completo (opcional)\n",
    "\n",
    "### ‚úÖ Resultado Esperado\n",
    "- **Taxa de sucesso**: ~100% (todos os leads processados)\n",
    "- **Features executadas**: Dependente das APIs configuradas\n",
    "- **Tempo**: Varia com o n√∫mero de APIs ativas\n",
    "- **Output**: Planilha Excel com todos os dados enriquecidos\n",
    "\n",
    "### üîß Corre√ß√µes Aplicadas\n",
    "- ‚úÖ Import correto do APIManager (c√©lula 00)\n",
    "- ‚úÖ Uso correto do atributo 'clients' do APIManager\n",
    "- ‚úÖ Conex√£o garantida entre api_manager e processor\n",
    "- ‚úÖ Processamento de TODOS os leads\n",
    "- ‚úÖ Skip apenas da API Google Maps para leads com ID\n",
    "- ‚úÖ Implementa√ß√£o de chamadas reais √†s APIs\n",
    "\n",
    "### ‚ö° Dicas de Performance\n",
    "- Configure o m√°ximo de APIs poss√≠vel para melhores resultados\n",
    "- Use `quick_test()` primeiro para validar\n",
    "- Ajuste `batch_size` e `max_concurrent_tasks` se necess√°rio\n",
    "- Monitore o uso de cotas das APIs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}