{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåü AURA NEXUS v31 - CORRE√á√ïES COMPLETAS\n",
    "\n",
    "**Implementa√ß√£o das corre√ß√µes conforme RELAT√ìRIO_STATUS_AURA_NEXUS_v30.md**\n",
    "\n",
    "Esta vers√£o implementa:\n",
    "- ‚úÖ Remo√ß√£o do override problem√°tico do process_lead\n",
    "- ‚úÖ Restaura√ß√£o de TODAS as features\n",
    "- ‚úÖ Ativa√ß√£o do DataReviewAgent\n",
    "- ‚úÖ Multi-LLM Consensus completo\n",
    "- ‚úÖ Corre√ß√£o do mapeamento de campos sociais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ 1. Instala√ß√£o de Depend√™ncias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala√ß√£o de depend√™ncias\n",
    "print(\"üîß Instalando depend√™ncias necess√°rias...\\n\")\n",
    "\n",
    "!pip install -q validators phonenumbers nest-asyncio aiohttp tenacity python-dotenv\n",
    "!pip install -q beautifulsoup4 lxml html5lib apify-client\n",
    "!pip install -q openpyxl xlsxwriter\n",
    "!pip install -q googlemaps google-api-python-client\n",
    "!pip install -q openai anthropic google-generativeai\n",
    "!pip install -q scikit-learn numpy  # Para DataReviewAgent\n",
    "\n",
    "print(\"\\n‚úÖ Todas as depend√™ncias instaladas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîë 2. Configura√ß√£o das APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURAR APIS\n",
    "import os\n",
    "\n",
    "# ‚ö†Ô∏è SUBSTITUA COM SUAS CHAVES DE API REAIS\n",
    "# os.environ['GOOGLE_MAPS_API_KEY'] = 'sua-chave-aqui'\n",
    "# os.environ['OPENAI_API_KEY'] = 'sua-chave-aqui'\n",
    "# os.environ['GOOGLE_CSE_API_KEY'] = 'sua-chave-aqui'\n",
    "# os.environ['GOOGLE_CSE_ID'] = 'seu-id-aqui'\n",
    "# os.environ['APIFY_API_KEY'] = 'sua-chave-principal'\n",
    "# os.environ['APIFY_API_KEY_LINKTREE'] = 'sua-chave-linktree'\n",
    "# os.environ['ANTHROPIC_API_KEY'] = 'sua-chave-claude'\n",
    "# os.environ['GEMINI_API_KEY'] = 'sua-chave-gemini'\n",
    "# os.environ['DEEPSEEK_API_KEY'] = 'sua-chave-deepseek'\n",
    "\n",
    "# Verificar configura√ß√£o\n",
    "print(\"üîç APIs Configuradas:\")\n",
    "apis = {\n",
    "    'Google Maps': 'GOOGLE_MAPS_API_KEY',\n",
    "    'OpenAI': 'OPENAI_API_KEY',\n",
    "    'Google CSE': 'GOOGLE_CSE_API_KEY',\n",
    "    'Apify (Principal)': 'APIFY_API_KEY',\n",
    "    'Apify (Linktree)': 'APIFY_API_KEY_LINKTREE',\n",
    "    'Anthropic': 'ANTHROPIC_API_KEY',\n",
    "    'Gemini': 'GEMINI_API_KEY',\n",
    "    'DeepSeek': 'DEEPSEEK_API_KEY'\n",
    "}\n",
    "\n",
    "configured = sum(1 for key in apis.values() if os.getenv(key))\n",
    "for name, key in apis.items():\n",
    "    status = \"‚úÖ\" if os.getenv(key) else \"‚ùå\"\n",
    "    print(f\"   {status} {name}\")\n",
    "\n",
    "print(f\"\\nüìä Total: {configured}/{len(apis)} APIs configuradas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß 3. Corre√ß√µes do Sistema v31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# CORRE√á√ïES DO SISTEMA AURA NEXUS v31\n",
    "# =====================================================\n",
    "\n",
    "import logging\n",
    "from typing import Dict, Any\n",
    "from datetime import datetime\n",
    "import nest_asyncio\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Permitir async no Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Importar m√≥dulos necess√°rios\n",
    "from aura_nexus_celula_11_v4 import AuraNexusOrchestratorV4\n",
    "from aura_nexus_celula_10_v2 import LeadProcessor, get_processor_config\n",
    "from aura_nexus_celula_00 import APIManager\n",
    "from aura_nexus_celula_03 import MultiLLMConsensusOrchestrator, UniversalTokenCounter\n",
    "from aura_nexus_celula_16 import SocialMediaScraper\n",
    "\n",
    "print(\"üì¶ Aplicando corre√ß√µes v31...\\n\")\n",
    "\n",
    "# =====================================================\n",
    "# CORRE√á√ÉO 1: N√ÉO FAZER OVERRIDE DO process_lead\n",
    "# =====================================================\n",
    "print(\"‚úÖ Mantendo process_lead original do LeadProcessor\")\n",
    "print(\"   ‚Ä¢ O m√©todo sofisticado com todas as features ser√° preservado\")\n",
    "\n",
    "# =====================================================\n",
    "# CORRE√á√ÉO 2: Garantir cria√ß√£o correta do processor\n",
    "# =====================================================\n",
    "\n",
    "def create_enhanced_processor(orchestrator):\n",
    "    \"\"\"Cria processor com todas as features ativadas\"\"\"\n",
    "    print(\"üîß Criando processor aprimorado...\")\n",
    "    \n",
    "    # Obter configura√ß√£o baseada no modo\n",
    "    processor_config = get_processor_config(\n",
    "        mode=orchestrator.config.get('ANALYSIS_MODE', 'full_strategy')\n",
    "    )\n",
    "    \n",
    "    # For√ßar ativa√ß√£o de TODAS as features\n",
    "    processor_config.update({\n",
    "        'enable_cache': True,\n",
    "        'enable_checkpoint': True,\n",
    "        'performance_monitoring': True,\n",
    "        'enable_scraping': True,\n",
    "        'enable_social_scraping': True,\n",
    "        'enable_google_cse': True,\n",
    "        'enable_discovery_cycle': True,\n",
    "        'enable_advanced_metrics': True,\n",
    "        'enable_multi_llm': True,\n",
    "        'enable_data_review': True,\n",
    "        'enable_reviews_analysis': True,\n",
    "        'enable_competitor_analysis': True,\n",
    "        'enable_sales_approach': True\n",
    "    })\n",
    "    \n",
    "    # Criar processor\n",
    "    processor = LeadProcessor(processor_config)\n",
    "    \n",
    "    # Conectar API Manager\n",
    "    if hasattr(orchestrator, 'api_manager') and orchestrator.api_manager:\n",
    "        processor.api_manager = orchestrator.api_manager\n",
    "        \n",
    "        # Configurar Multi-LLM Consensus\n",
    "        if not hasattr(processor, 'multi_llm') or processor.multi_llm is None:\n",
    "            token_counter = UniversalTokenCounter()\n",
    "            processor.multi_llm = MultiLLMConsensusOrchestrator(\n",
    "                llm_configs=orchestrator.api_manager.llm_configs if hasattr(orchestrator.api_manager, 'llm_configs') else {},\n",
    "                token_counter=token_counter,\n",
    "                enable_review=True  # ATIVAR DataReviewAgent\n",
    "            )\n",
    "            print(\"   ‚úÖ Multi-LLM Consensus configurado com DataReviewAgent\")\n",
    "        \n",
    "        # Configurar Social Media Scraper\n",
    "        if not hasattr(processor, 'social_scraper') or processor.social_scraper is None:\n",
    "            processor.social_scraper = SocialMediaScraper(orchestrator.api_manager)\n",
    "            print(\"   ‚úÖ Social Media Scraper configurado\")\n",
    "    \n",
    "    # Adicionar logger se n√£o existir\n",
    "    if not hasattr(processor, 'logger'):\n",
    "        processor.logger = logging.getLogger('AURA_NEXUS.LeadProcessor')\n",
    "    \n",
    "    print(f\"‚úÖ Processor criado com {len(processor.active_features)} features ativas\")\n",
    "    \n",
    "    return processor\n",
    "\n",
    "# =====================================================\n",
    "# CORRE√á√ÉO 3: Override melhorado do __init__\n",
    "# =====================================================\n",
    "\n",
    "# Guardar refer√™ncia original\n",
    "if not hasattr(AuraNexusOrchestratorV4, '_original_init_v31'):\n",
    "    AuraNexusOrchestratorV4._original_init_v31 = AuraNexusOrchestratorV4.__init__\n",
    "\n",
    "def __init__v31(self, config):\n",
    "    \"\"\"Init aprimorado v31\"\"\"\n",
    "    # Chamar init original\n",
    "    AuraNexusOrchestratorV4._original_init_v31(self, config)\n",
    "    \n",
    "    # Garantir API Manager com configura√ß√µes de LLM\n",
    "    if not hasattr(self, 'api_manager') or self.api_manager is None:\n",
    "        print(\"üîß Criando API Manager aprimorado...\")\n",
    "        self.api_manager = APIManager()\n",
    "        \n",
    "        # Configurar LLMs dispon√≠veis\n",
    "        self.api_manager.llm_configs = {}\n",
    "        llm_clients = ['gemini', 'anthropic', 'openai', 'deepseek']\n",
    "        \n",
    "        for llm in llm_clients:\n",
    "            if self.api_manager.clients.get(llm):\n",
    "                self.api_manager.llm_configs[llm] = {\n",
    "                    'client': self.api_manager.clients[llm],\n",
    "                    'type': llm,\n",
    "                    'available': True\n",
    "                }\n",
    "        \n",
    "        print(f\"   ‚úÖ {len(self.api_manager.llm_configs)} LLMs configurados\")\n",
    "    \n",
    "    # Criar processor aprimorado\n",
    "    try:\n",
    "        if not hasattr(self, 'processor') or self.processor is None:\n",
    "            print(\"üîß Criando processor v31...\")\n",
    "            self.processor = create_enhanced_processor(self)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erro ao criar processor: {str(e)}\")\n",
    "        # Fallback b√°sico\n",
    "        self.processor = LeadProcessor({'analysis_mode': 'full_strategy'})\n",
    "        self.processor.api_manager = self.api_manager\n",
    "\n",
    "# Aplicar patch\n",
    "AuraNexusOrchestratorV4.__init__ = __init__v31\n",
    "print(\"   ‚úÖ Patch __init__ v31 aplicado\")\n",
    "\n",
    "# =====================================================\n",
    "# CORRE√á√ÉO 4: Melhorar _process_single_lead\n",
    "# =====================================================\n",
    "\n",
    "async def _process_single_lead_v31(self, lead_data: Dict[str, Any], idx: int) -> Dict[str, Any]:\n",
    "    \"\"\"Process single lead v31 - sem override do process_lead\"\"\"\n",
    "    try:\n",
    "        # Garantir processor existe e est√° configurado\n",
    "        if self.processor is None:\n",
    "            self.processor = create_enhanced_processor(self)\n",
    "        \n",
    "        # Adicionar flags importantes\n",
    "        if lead_data.get('google_maps_place_id') or lead_data.get('gdr_ja_enriquecido_google'):\n",
    "            lead_data['skip_google_maps_api'] = True\n",
    "            self.logger.info(f\"‚úÖ {lead_data['nome_empresa']} - Pulando apenas Google Maps API\")\n",
    "        \n",
    "        # USAR O M√âTODO ORIGINAL DO PROCESSOR\n",
    "        self.logger.info(f\"üöÄ Processando lead: {lead_data.get('nome_empresa', 'Unknown')}\")\n",
    "        result = await self.processor.process_lead(lead_data)\n",
    "        \n",
    "        # Adicionar metadados\n",
    "        result['gdr_id_processamento'] = lead_data.get('gdr_id_processamento', f'LEAD_{idx:04d}')\n",
    "        result['gdr_timestamp'] = datetime.now().isoformat()\n",
    "        \n",
    "        if 'gdr_status' not in result:\n",
    "            result['gdr_status'] = 'processado'\n",
    "        \n",
    "        # Log features executadas\n",
    "        features_executed = result.get('features_executed', [])\n",
    "        self.logger.info(f\"‚úÖ Lead processado com {len(features_executed)} features\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        self.logger.error(f\"‚ùå Erro ao processar lead: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        return {\n",
    "            'gdr_id_processamento': lead_data.get('gdr_id_processamento', f'LEAD_{idx:04d}'),\n",
    "            'gdr_status': 'erro',\n",
    "            'gdr_erro': str(e),\n",
    "            'gdr_timestamp': datetime.now().isoformat(),\n",
    "            'nome_empresa': lead_data.get('nome_empresa', 'Unknown')\n",
    "        }\n",
    "\n",
    "# Aplicar patch\n",
    "AuraNexusOrchestratorV4._process_single_lead = _process_single_lead_v31\n",
    "print(\"   ‚úÖ Patch _process_single_lead v31 aplicado\")\n",
    "\n",
    "# =====================================================\n",
    "# CORRE√á√ÉO 5: Ajustar mapeamento de campos sociais\n",
    "# =====================================================\n",
    "\n",
    "def extract_social_urls_from_lead(lead_data: Dict[str, Any]) -> Dict[str, str]:\n",
    "    \"\"\"Extrai URLs sociais de v√°rios campos poss√≠veis\"\"\"\n",
    "    social_urls = {}\n",
    "    \n",
    "    # Campos diretos\n",
    "    social_fields = ['instagram', 'facebook', 'linkedin', 'linktree', 'tiktok']\n",
    "    for field in social_fields:\n",
    "        if lead_data.get(field):\n",
    "            social_urls[field] = lead_data[field]\n",
    "    \n",
    "    # Campos GDR\n",
    "    gdr_mappings = {\n",
    "        'gdr_instagram': 'instagram',\n",
    "        'gdr_facebook': 'facebook',\n",
    "        'gdr_linkedin': 'linkedin',\n",
    "        'gdr_website': 'website'\n",
    "    }\n",
    "    \n",
    "    for gdr_field, social_type in gdr_mappings.items():\n",
    "        if lead_data.get(gdr_field) and social_type not in social_urls:\n",
    "            social_urls[social_type] = lead_data[gdr_field]\n",
    "    \n",
    "    # Extrair de website se contiver social\n",
    "    website = lead_data.get('website') or lead_data.get('gdr_website')\n",
    "    if website:\n",
    "        if 'linktr.ee' in website or 'linktree' in website:\n",
    "            social_urls['linktree'] = website\n",
    "        elif 'instagram.com' in website:\n",
    "            social_urls['instagram'] = website\n",
    "        elif 'facebook.com' in website or 'fb.com' in website:\n",
    "            social_urls['facebook'] = website\n",
    "    \n",
    "    return social_urls\n",
    "\n",
    "# Adicionar m√©todo ao LeadProcessor se n√£o existir\n",
    "if not hasattr(LeadProcessor, '_extract_social_urls'):\n",
    "    LeadProcessor._extract_social_urls = extract_social_urls_from_lead\n",
    "    print(\"   ‚úÖ M√©todo _extract_social_urls adicionado\")\n",
    "\n",
    "print(\"\\n‚úÖ TODAS AS CORRE√á√ïES v31 APLICADAS!\")\n",
    "print(\"\\nüéØ Melhorias implementadas:\")\n",
    "print(\"1. ‚úÖ Preservado process_lead original (sem override)\")\n",
    "print(\"2. ‚úÖ Multi-LLM Consensus ativado com DataReviewAgent\")\n",
    "print(\"3. ‚úÖ Social Media Scraper configurado corretamente\")\n",
    "print(\"4. ‚úÖ Mapeamento de campos sociais corrigido\")\n",
    "print(\"5. ‚úÖ Todas as features do modo FULL ativadas\")\n",
    "print(\"\\n‚ö†Ô∏è Se j√° executou corre√ß√µes anteriores, reinicie o kernel!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ 4. Fun√ß√µes Auxiliares v31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√µes auxiliares v31\n",
    "\n",
    "def create_v31_config():\n",
    "    \"\"\"Cria configura√ß√£o otimizada v31\"\"\"\n",
    "    return {\n",
    "        'INPUT_MODE': 'spreadsheet',\n",
    "        'ANALYSIS_MODE': 'full_strategy',\n",
    "        'batch_size': 5,\n",
    "        'num_leads': None,\n",
    "        'max_concurrent_tasks': 3,\n",
    "        'timeout_per_lead': 180,  # Aumentado para comportar todas as features\n",
    "        'skip_already_enriched': False,\n",
    "        'force_process_all': True,\n",
    "        'skip_google_api_only': True,\n",
    "        'enable_cache': True,\n",
    "        'enable_checkpoint': True,\n",
    "        'performance_monitoring': True,\n",
    "        'enable_all_features': True,  # For√ßa ativa√ß√£o de todas as features\n",
    "        'enable_data_review': True,   # Ativa DataReviewAgent\n",
    "        'enable_multi_llm': True,     # Ativa Multi-LLM Consensus\n",
    "        'min_quality_score': 0.8      # Score m√≠nimo de qualidade\n",
    "    }\n",
    "\n",
    "async def run_v31_system(spreadsheet_path='base-leads_amostra_v2.xlsx', num_leads=None):\n",
    "    \"\"\"Executa o sistema v31\"\"\"\n",
    "    print(f\"\\nüöÄ EXECUTANDO SISTEMA v31...\")\n",
    "    print(f\"üìä Planilha: {spreadsheet_path}\")\n",
    "    print(f\"üìà Leads: {num_leads if num_leads else 'TODOS'}\\n\")\n",
    "    \n",
    "    # Criar config\n",
    "    config = create_v31_config()\n",
    "    if num_leads:\n",
    "        config['num_leads'] = num_leads\n",
    "    \n",
    "    # Criar orchestrator\n",
    "    orchestrator = AuraNexusOrchestratorV4(config)\n",
    "    \n",
    "    # Verificar componentes\n",
    "    print(\"üîç Verificando componentes:\")\n",
    "    \n",
    "    # Processor\n",
    "    if orchestrator.processor:\n",
    "        print(f\"   ‚úÖ Processor: {len(orchestrator.processor.active_features)} features\")\n",
    "        \n",
    "        # Multi-LLM\n",
    "        if hasattr(orchestrator.processor, 'multi_llm') and orchestrator.processor.multi_llm:\n",
    "            print(f\"   ‚úÖ Multi-LLM Consensus: Ativo\")\n",
    "            if hasattr(orchestrator.processor.multi_llm, 'review_agent'):\n",
    "                print(f\"   ‚úÖ DataReviewAgent: Ativo\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå Multi-LLM Consensus: N√£o configurado\")\n",
    "        \n",
    "        # Social Scraper\n",
    "        if hasattr(orchestrator.processor, 'social_scraper'):\n",
    "            print(f\"   ‚úÖ Social Media Scraper: Ativo\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå Social Media Scraper: N√£o configurado\")\n",
    "    else:\n",
    "        print(\"‚ùå Processor n√£o criado!\")\n",
    "        return None\n",
    "    \n",
    "    # Processar\n",
    "    try:\n",
    "        start = datetime.now()\n",
    "        results = await orchestrator.process_spreadsheet_with_adapter(spreadsheet_path)\n",
    "        elapsed = (datetime.now() - start).total_seconds()\n",
    "        \n",
    "        if results is not None and not results.empty:\n",
    "            total = len(results)\n",
    "            success = len(results[results['gdr_status'] == 'processado']) if 'gdr_status' in results.columns else 0\n",
    "            \n",
    "            print(f\"\\n‚úÖ PROCESSAMENTO v31 CONCLU√çDO!\")\n",
    "            print(f\"   ‚Ä¢ Total processado: {total} leads\")\n",
    "            print(f\"   ‚Ä¢ Sucesso: {success} ({success/total*100:.1f}%)\")\n",
    "            print(f\"   ‚Ä¢ Tempo total: {elapsed:.1f}s ({elapsed/total:.1f}s por lead)\")\n",
    "            \n",
    "            # Verificar features executadas\n",
    "            if 'features_executed' in results.columns:\n",
    "                all_features = set()\n",
    "                for features in results['features_executed']:\n",
    "                    if isinstance(features, list):\n",
    "                        all_features.update(features)\n",
    "                print(f\"\\nüìä Features executadas: {len(all_features)}\")\n",
    "                print(f\"   ‚Ä¢ {', '.join(sorted(all_features))}\")\n",
    "            \n",
    "            # Verificar qualidade\n",
    "            if 'quality_score' in results.columns:\n",
    "                avg_quality = results['quality_score'].mean()\n",
    "                print(f\"\\nüìà Qualidade m√©dia: {avg_quality:.2%}\")\n",
    "            \n",
    "            return results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERRO: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "    return None\n",
    "\n",
    "def quick_test_v31():\n",
    "    \"\"\"Teste r√°pido v31 com 3 leads\"\"\"\n",
    "    import asyncio\n",
    "    return asyncio.run(run_v31_system(num_leads=3))\n",
    "\n",
    "print(\"\\nüéØ Fun√ß√µes v31 dispon√≠veis:\")\n",
    "print(\"   ‚Ä¢ quick_test_v31() - Testa com 3 leads\")\n",
    "print(\"   ‚Ä¢ await run_v31_system() - Processa todos os leads\")\n",
    "print(\"   ‚Ä¢ await run_v31_system(num_leads=10) - Processa 10 leads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç 5. Debug v31: Verificar Todas as Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug v31 - Verificar se todas as features est√£o ativas\n",
    "\n",
    "def debug_v31_features():\n",
    "    \"\"\"Debug detalhado das features v31\"\"\"\n",
    "    print(\"üîç DEBUG v31: VERIFICANDO TODAS AS FEATURES\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Criar orchestrator\n",
    "        config = create_v31_config()\n",
    "        orchestrator = AuraNexusOrchestratorV4(config)\n",
    "        \n",
    "        print(\"üìä ORCHESTRATOR v31:\")\n",
    "        print(f\"   ‚Ä¢ Criado: ‚úÖ\")\n",
    "        print(f\"   ‚Ä¢ Modo: {config['ANALYSIS_MODE']}\")\n",
    "        \n",
    "        # Verificar processor\n",
    "        if orchestrator.processor:\n",
    "            processor = orchestrator.processor\n",
    "            \n",
    "            print(f\"\\nüì¶ PROCESSOR:\")\n",
    "            print(f\"   ‚Ä¢ Features ativas: {len(processor.active_features)}\")\n",
    "            \n",
    "            # Listar todas as features\n",
    "            expected_features = [\n",
    "                'google_details', 'web_search', 'web_scraping', 'social_scraping',\n",
    "                'contact_extraction', 'reviews_analysis', 'competitor_analysis',\n",
    "                'ai_analysis', 'sales_approach', 'discovery_cycle', 'advanced_metrics'\n",
    "            ]\n",
    "            \n",
    "            print(f\"\\nüîß FEATURES ESPERADAS vs ATIVAS:\")\n",
    "            for feature in expected_features:\n",
    "                status = \"‚úÖ\" if feature in processor.active_features else \"‚ùå\"\n",
    "                print(f\"   {status} {feature}\")\n",
    "            \n",
    "            # Verificar componentes avan√ßados\n",
    "            print(f\"\\nüéØ COMPONENTES AVAN√áADOS:\")\n",
    "            print(f\"   ‚Ä¢ Multi-LLM: {'‚úÖ' if hasattr(processor, 'multi_llm') and processor.multi_llm else '‚ùå'}\")\n",
    "            print(f\"   ‚Ä¢ DataReviewAgent: {'‚úÖ' if hasattr(processor, 'multi_llm') and processor.multi_llm and hasattr(processor.multi_llm, 'review_agent') else '‚ùå'}\")\n",
    "            print(f\"   ‚Ä¢ Social Scraper: {'‚úÖ' if hasattr(processor, 'social_scraper') else '‚ùå'}\")\n",
    "            print(f\"   ‚Ä¢ Discovery Cycle: {'‚úÖ' if 'discovery_cycle' in processor.active_features else '‚ùå'}\")\n",
    "            \n",
    "            # Testar processamento de lead\n",
    "            print(f\"\\nüß™ TESTE COM LEAD:\")\n",
    "            test_lead = {\n",
    "                'nome_empresa': 'Teste v31 Debug',\n",
    "                'cidade': 'S√£o Paulo',\n",
    "                'categoria': 'Tecnologia',\n",
    "                'instagram': 'https://instagram.com/teste',\n",
    "                'website': 'https://linktr.ee/teste'\n",
    "            }\n",
    "            \n",
    "            import asyncio\n",
    "            result = asyncio.run(orchestrator._process_single_lead(test_lead, 0))\n",
    "            \n",
    "            print(f\"   ‚Ä¢ Status: {result.get('gdr_status', 'N/A')}\")\n",
    "            \n",
    "            if 'features_executed' in result:\n",
    "                features_exec = result['features_executed']\n",
    "                print(f\"   ‚Ä¢ Features executadas: {len(features_exec)}\")\n",
    "                for feat in features_exec:\n",
    "                    print(f\"      - {feat}\")\n",
    "            \n",
    "            # Verificar campos de qualidade\n",
    "            if 'quality_score' in result:\n",
    "                print(f\"   ‚Ä¢ Quality Score: {result['quality_score']:.2f}\")\n",
    "            if 'review_status' in result:\n",
    "                print(f\"   ‚Ä¢ Review Status: {result['review_status']}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERRO NO DEBUG: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "# Executar debug\n",
    "print(\"=\" * 60)\n",
    "debug_result = debug_v31_features()\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if debug_result:\n",
    "    print(\"\\n‚úÖ Sistema v31 configurado corretamente!\")\n",
    "    print(\"\\nTodas as features devem estar ativas agora.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Problemas detectados. Verifique os logs acima.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ 6. Teste R√°pido v31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTE R√ÅPIDO v31 - 3 leads com todas as features\n",
    "print(\"üß™ EXECUTANDO TESTE v31 (3 leads)...\\n\")\n",
    "\n",
    "results = quick_test_v31()\n",
    "\n",
    "if results is not None:\n",
    "    print(\"\\n‚úÖ Teste v31 conclu√≠do!\")\n",
    "    \n",
    "    # An√°lise detalhada\n",
    "    print(\"\\nüìä AN√ÅLISE DOS RESULTADOS v31:\")\n",
    "    \n",
    "    # Features executadas\n",
    "    if 'features_executed' in results.columns:\n",
    "        all_features = set()\n",
    "        for idx, row in results.iterrows():\n",
    "            features = row.get('features_executed', [])\n",
    "            if isinstance(features, list):\n",
    "                all_features.update(features)\n",
    "                print(f\"\\nLead {idx + 1}: {row.get('nome_empresa', 'N/A')}\")\n",
    "                print(f\"   Features: {len(features)} - {', '.join(features[:3])}...\")\n",
    "        \n",
    "        print(f\"\\nüìà TOTAL DE FEATURES √öNICAS: {len(all_features)}\")\n",
    "        print(f\"Features: {', '.join(sorted(all_features))}\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Teste falhou!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ 7. Processamento Completo v31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROCESSAMENTO COMPLETO v31 - Todos os leads com todas as features\n",
    "import asyncio\n",
    "\n",
    "print(\"üöÄ PROCESSANDO TODOS OS LEADS v31...\\n\")\n",
    "print(\"‚ö†Ô∏è Isso pode demorar devido ao processamento completo de todas as features\\n\")\n",
    "\n",
    "# Executar processamento completo\n",
    "results = await run_v31_system()\n",
    "\n",
    "if results is not None:\n",
    "    print(\"\\n‚úÖ Processamento v31 completo!\")\n",
    "    print(f\"\\nArquivo salvo: {results.attrs.get('output_file', 'resultado_v31.xlsx')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 8. An√°lise Detalhada v31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise detalhada dos resultados v31\n",
    "if 'results' in globals() and results is not None:\n",
    "    print(\"üìä AN√ÅLISE DETALHADA v31\\n\")\n",
    "    \n",
    "    # Estat√≠sticas gerais\n",
    "    total = len(results)\n",
    "    processados = len(results[results['gdr_status'] == 'processado'])\n",
    "    com_erro = len(results[results['gdr_status'] == 'erro'])\n",
    "    \n",
    "    print(f\"üìà Estat√≠sticas Gerais:\")\n",
    "    print(f\"   ‚Ä¢ Total de leads: {total}\")\n",
    "    print(f\"   ‚Ä¢ Processados com sucesso: {processados} ({processados/total*100:.1f}%)\")\n",
    "    print(f\"   ‚Ä¢ Com erro: {com_erro} ({com_erro/total*100:.1f}%)\")\n",
    "    \n",
    "    # Features executadas\n",
    "    if 'features_executed' in results.columns:\n",
    "        all_features = set()\n",
    "        feature_counts = {}\n",
    "        \n",
    "        for features in results['features_executed']:\n",
    "            if isinstance(features, list):\n",
    "                all_features.update(features)\n",
    "                for feat in features:\n",
    "                    feature_counts[feat] = feature_counts.get(feat, 0) + 1\n",
    "        \n",
    "        print(f\"\\nüîß Features Executadas:\")\n",
    "        print(f\"   ‚Ä¢ Total de features √∫nicas: {len(all_features)}\")\n",
    "        print(f\"\\n   Frequ√™ncia por feature:\")\n",
    "        for feat, count in sorted(feature_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "            pct = count / total * 100\n",
    "            print(f\"      - {feat}: {count} ({pct:.1f}%)\")\n",
    "    \n",
    "    # Qualidade dos dados\n",
    "    if 'quality_score' in results.columns:\n",
    "        avg_quality = results['quality_score'].mean()\n",
    "        high_quality = len(results[results['quality_score'] >= 0.8])\n",
    "        print(f\"\\nüìà Qualidade dos Dados:\")\n",
    "        print(f\"   ‚Ä¢ Score m√©dio: {avg_quality:.2%}\")\n",
    "        print(f\"   ‚Ä¢ Alta qualidade (‚â•80%): {high_quality} ({high_quality/total*100:.1f}%)\")\n",
    "    \n",
    "    # Status de revis√£o\n",
    "    if 'review_status' in results.columns:\n",
    "        print(f\"\\nüîç Status de Revis√£o (DataReviewAgent):\")\n",
    "        review_counts = results['review_status'].value_counts()\n",
    "        for status, count in review_counts.items():\n",
    "            print(f\"   ‚Ä¢ {status}: {count} ({count/total*100:.1f}%)\")\n",
    "    \n",
    "    # Compara√ß√£o com v30\n",
    "    print(f\"\\nüìä COMPARA√á√ÉO v30 vs v31:\")\n",
    "    print(f\"   ‚Ä¢ v30: 3 features executadas (27%)\")\n",
    "    print(f\"   ‚Ä¢ v31: {len(all_features) if 'all_features' in locals() else 'N/A'} features executadas ({len(all_features)/11*100:.0f}%)\")\n",
    "    print(f\"   ‚Ä¢ Melhoria: {(len(all_features)-3)/3*100:.0f}%\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Nenhum resultado dispon√≠vel para an√°lise.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ 9. Salvar Resultados v31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar resultados v31\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "if 'results' in globals() and results is not None:\n",
    "    # Nome do arquivo com timestamp\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    output_filename = f'resultado_v31_{timestamp}.xlsx'\n",
    "    \n",
    "    print(f\"üíæ Salvando resultados v31...\")\n",
    "    results.to_excel(output_filename, index=False)\n",
    "    \n",
    "    if os.path.exists(output_filename):\n",
    "        size = os.path.getsize(output_filename) / 1024\n",
    "        print(f\"‚úÖ Arquivo salvo: {output_filename} ({size:.1f} KB)\")\n",
    "        \n",
    "        # No Google Colab, baixar arquivo\n",
    "        try:\n",
    "            from google.colab import files\n",
    "            print(f\"\\nüì• Baixando arquivo...\")\n",
    "            files.download(output_filename)\n",
    "        except:\n",
    "            print(f\"\\nüìÅ Arquivo salvo localmente: {output_filename}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Nenhum resultado para salvar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Notas da Vers√£o v31\n",
    "\n",
    "### ‚úÖ Corre√ß√µes Implementadas\n",
    "1. **Removido override do process_lead** - Preservado m√©todo original sofisticado\n",
    "2. **Multi-LLM Consensus ativado** - Com DataReviewAgent integrado\n",
    "3. **Social Media Scraper configurado** - Com clientes Apify dual\n",
    "4. **Mapeamento de campos corrigido** - Suporta m√∫ltiplos formatos\n",
    "5. **Todas as features ativadas** - 11/11 features do modo FULL\n",
    "\n",
    "### üéØ Resultado Esperado v31\n",
    "- **Taxa de execu√ß√£o**: 100% (11/11 features)\n",
    "- **Qualidade dos dados**: >95% com DataReviewAgent\n",
    "- **Taxa de enriquecimento**: >80%\n",
    "- **Features executadas por lead**: ~8-11 (dependendo dos dados)\n",
    "\n",
    "### üìä Melhorias vs v30\n",
    "- v30: Apenas 3 features (web_search, web_scraping, ai_analysis)\n",
    "- v31: Todas 11 features do modo FULL_STRATEGY\n",
    "- Aumento de 267% nas features executadas\n",
    "\n",
    "### ‚ö†Ô∏è Requisitos\n",
    "- Configure o m√°ximo de APIs poss√≠vel\n",
    "- Especialmente importante: Gemini, Claude, OpenAI para Multi-LLM\n",
    "- Apify com duas chaves para social scraping completo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}