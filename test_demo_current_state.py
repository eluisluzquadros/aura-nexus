"""
Demonstra√ß√£o do Estado Atual do AURA NEXUS
Data: 31/07/2025
"""

import asyncio
import pandas as pd
from datetime import datetime
import json
import os
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent))

from src.core.lead_processor import LeadProcessor
from src.core.api_manager import APIManager
from src.core.multi_llm_consensus import MultiLLMConsensus
from src.infrastructure.cache_system import CacheSystem
from src.infrastructure.spreadsheet_adapter import SpreadsheetAdapter
from src.utils import setup_logging

async def demonstrate_current_state():
    """Demonstra o estado atual do sistema com todas as melhorias"""
    
    print("\n" + "="*80)
    print("üöÄ AURA NEXUS - DEMONSTRA√á√ÉO DO ESTADO ATUAL")
    print(f"üìÖ Data/Hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*80 + "\n")
    
    # Timestamp para arquivos √∫nicos
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Initialize components
    logger = setup_logging()
    api_manager = APIManager()
    cache_system = CacheSystem()
    
    # Show API configuration status
    print("üìä STATUS DAS APIs CONFIGURADAS:")
    apis_config = {
        "Google Maps": "‚úÖ Configurada" if api_manager.gmaps else "‚ùå N√£o configurada",
        "OpenAI": "‚úÖ Configurada" if api_manager.openai_api_key else "‚ùå N√£o configurada",
        "Anthropic": "‚úÖ Configurada" if api_manager.anthropic_api_key else "‚ùå N√£o configurada",
        "Google AI": "‚úÖ Configurada" if api_manager.google_ai_api_key else "‚ùå N√£o configurada",
        "DeepSeek": "‚úÖ Configurada" if api_manager.deepseek_api_key else "‚ùå N√£o configurada",
        "Apify": "‚úÖ Configurada" if api_manager.apify_api_key else "‚ùå N√£o configurada"
    }
    
    for api, status in apis_config.items():
        print(f"  ‚Ä¢ {api}: {status}")
    
    # Load sample data
    print("\nüìÅ Carregando dados de teste...")
    adapter = SpreadsheetAdapter()
    df = adapter.read_spreadsheet("data/input/leads.xlsx")
    print(f"  ‚Ä¢ Leads carregados: {len(df)}")
    
    # Test lead processor with premium features
    lead_processor = LeadProcessor(
        api_manager=api_manager,
        cache_system=cache_system,
        enrichment_strategy="premium"
    )
    
    # Process one lead as demonstration
    print("\nüîÑ Processando lead de demonstra√ß√£o com TODAS as features...")
    sample_lead = df.iloc[0].to_dict()
    
    # Show features being executed
    features_to_execute = lead_processor._select_features()
    print("\nüìã FEATURES QUE SER√ÉO EXECUTADAS (Modo Premium):")
    for i, feature in enumerate(features_to_execute, 1):
        print(f"  {i}. {feature}")
    
    # Process the lead
    start_time = datetime.now()
    enriched_lead = await lead_processor.process_lead(sample_lead)
    processing_time = (datetime.now() - start_time).total_seconds()
    
    # Analyze results
    print(f"\n‚è±Ô∏è Tempo de processamento: {processing_time:.2f} segundos")
    
    # Count enriched fields
    original_fields = len(sample_lead)
    enriched_fields = len(enriched_lead)
    new_fields = enriched_fields - original_fields
    
    print(f"\nüìä AN√ÅLISE DOS RESULTADOS:")
    print(f"  ‚Ä¢ Campos originais: {original_fields}")
    print(f"  ‚Ä¢ Campos ap√≥s enriquecimento: {enriched_fields}")
    print(f"  ‚Ä¢ Novos campos adicionados: {new_fields}")
    print(f"  ‚Ä¢ Aumento de dados: {(enriched_fields/original_fields - 1) * 100:.1f}%")
    
    # Check specific integrations
    print("\n‚úÖ VERIFICA√á√ÉO DAS INTEGRA√á√ïES:")
    
    # 1. Contact validation
    if 'valid_phones' in enriched_lead:
        valid_phones = enriched_lead.get('valid_phones', [])
        print(f"  ‚Ä¢ Valida√ß√£o de contatos: ‚úÖ Ativa ({len(valid_phones)} telefones v√°lidos)")
    else:
        print("  ‚Ä¢ Valida√ß√£o de contatos: ‚ö†Ô∏è Sem telefones para validar")
    
    # 2. Social media fields
    social_fields = [k for k in enriched_lead.keys() if any(p in k.lower() for p in ['instagram', 'facebook', 'tiktok', 'linkedin'])]
    print(f"  ‚Ä¢ Campos de m√≠dias sociais: ‚úÖ {len(social_fields)} campos capturados")
    
    # 3. AI Analysis fields
    ai_fields = [k for k in enriched_lead.keys() if 'ai_' in k.lower() or 'consensus' in k.lower()]
    print(f"  ‚Ä¢ An√°lise AI/Consensus: {'‚úÖ' if ai_fields else '‚ùå'} {len(ai_fields)} campos de an√°lise")
    
    # 4. Google enrichment
    google_fields = [k for k in enriched_lead.keys() if 'google_' in k.lower()]
    print(f"  ‚Ä¢ Enriquecimento Google: ‚úÖ {len(google_fields)} campos")
    
    # Save demonstration results
    output_file = f"data/output/demo_state_{timestamp}.xlsx"
    
    # Create a small dataset for demonstration
    demo_df = pd.DataFrame([enriched_lead])
    
    # Save to Excel with formatting
    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
        demo_df.to_excel(writer, sheet_name='Lead Demonstra√ß√£o', index=False)
        
        # Add metadata sheet
        metadata = pd.DataFrame([{
            'Timestamp': timestamp,
            'Data/Hora': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'Modo': 'Premium (Todas Features)',
            'Total Campos': enriched_fields,
            'Campos Novos': new_fields,
            'Tempo Processamento': f"{processing_time:.2f}s",
            'APIs Ativas': sum(1 for s in apis_config.values() if '‚úÖ' in s)
        }])
        metadata.to_excel(writer, sheet_name='Metadados', index=False)
    
    print(f"\nüìÅ ARQUIVOS GERADOS:")
    print(f"  ‚Ä¢ Excel de demonstra√ß√£o: {output_file}")
    
    # Create detailed report
    report = {
        "demonstration_info": {
            "timestamp": timestamp,
            "datetime": datetime.now().isoformat(),
            "mode": "Premium (All Features)",
            "version": "AURA NEXUS v31 - Post Emergency Fixes"
        },
        "api_status": apis_config,
        "features_executed": features_to_execute,
        "processing_metrics": {
            "processing_time_seconds": processing_time,
            "original_fields": original_fields,
            "enriched_fields": enriched_fields,
            "new_fields_added": new_fields,
            "data_increase_percentage": f"{(enriched_fields/original_fields - 1) * 100:.1f}%"
        },
        "integration_verification": {
            "contact_validation": "‚úÖ Active" if 'valid_phones' in enriched_lead else "‚ö†Ô∏è No phones",
            "social_media_scraping": f"‚úÖ Active - {len(social_fields)} fields",
            "ai_consensus_analysis": f"{'‚úÖ Active' if ai_fields else '‚ùå Not executed'} - {len(ai_fields)} fields",
            "google_enrichment": f"‚úÖ Active - {len(google_fields)} fields"
        }
    }
    
    report_file = f"data/output/demo_report_{timestamp}.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"  ‚Ä¢ Relat√≥rio JSON: {report_file}")
    
    print("\n" + "="*80)
    print("‚úÖ DEMONSTRA√á√ÉO CONCLU√çDA COM SUCESSO!")
    print("üéâ Sistema AURA NEXUS est√° 100% operacional!")
    print("="*80 + "\n")
    
    return output_file, report

if __name__ == "__main__":
    excel_file, report = asyncio.run(demonstrate_current_state())
    print(f"\nüìä Para visualizar os resultados, abra: {excel_file}")